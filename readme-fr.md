<img src="/assets/jtbp-header-blue.png" width="1920px"/>

<br/>

# üëá Comment ce guide peut faire passer vos comp√©tences de test au niveau sup√©rieur

<br/>

## üìó 46+ bonnes pratiques : complet et exhaustif

Ceci est un guide complet pour Javascript & Node.js de A √† Z. Il r√©sume et organise pour vous les meilleurs articles de blogs, livres et outils du march√©

## üö¢ Avanc√© : va bien au-del√† des bases

Embarque pour un voyage qui va bien au-del√† des bases et aborde des sujets avanc√©s tels que les tests en production, les tests de mutations, les tests bas√©s sur les propri√©t√©s et de nombreux autres outils strat√©giques et professionnels. Si vous lisez chaque mot de ce guide, vos comp√©tences de tests seront probablement bien au-dessus la moyenne.

## üåê Full-stack: front, backend, CI ...

Commence par comprendre les pratiques de tests omnipr√©sentes qui sont √† la base de tout niveau d'application. Ensuite, plonge dans ton domaine de pr√©dilection : frontend/UI, backend, CI ou peut-√™tre tous √ßa √† la fois ?

<br/>

### √âcrit par Yoni Goldberg

- Un consultant JavaScript & Node.js
- üìó [Les tests Node.js & JavaScript de A √† Z](https://www.testjavascript.com) - Mon cours en ligne complet avec plus de [10 heures de video](https://www.testjavascript.com), 14 types de tests et plus de 40 bonnes pratiques
- [Suis-moi sur Twitter ](https://twitter.com/goldbergyoni/)

<br/>

### Traductions - Lis dans la langue de ton choix
- üá¨üáß[Anglais](readme.md)
- üá®üá≥[Chinois](readme-zh-CN.md) - Traduit par [Yves yao](https://github.com/yvesyao)
- üá∞üá∑[Cor√©en](readme.kr.md) - Traduit par [Rain Byun](https://github.com/ragubyun)
- üáµüá±[Polonais](readme-pl.md) - Traduit par [Michal Biesiada](https://github.com/mbiesiad)
- üá™üá∏[Espagnol](readme-es.md) - Traduit par [Miguel G. Sanguino](https://github.com/sanguino)
- üáßüá∑[Portugais br√©silien](readme-pt-br.md) - Traduit par [Iago Angelim Costa Cavalcante](https://github.com/iagocavalcante) , [Douglas Mariano Valero](https://github.com/DouglasMV) et [koooge](https://github.com/koooge)
- üá∫üá¶[Ukrainian](readme-ua.md) - Traduit par [Serhii Shramko](https://github.com/Shramkoweb)
- Envie de traduire dans ta propre langue ? Ouvres une issue üíú

<br/><br/>

## `Table des mati√®res`

#### [`Section 0: La r√®gle d'or`](#section-0Ô∏è‚É£-the-golden-rule)

Un seul conseil qui inspire tout les autres (1 point sp√©cial)

#### [`Section 1: Anatomie d'un test`](#section-1-the-test-anatomy-1)

La base - structurer des tests propre (12 points)

#### [`Section 2: Backend`](#section-2Ô∏è‚É£-backend-testing)

√âcrire efficacement des tests backend et de microservices (8 points)

#### [`Section 3: Frontend`](#section-3Ô∏è‚É£-frontend-testing)

√âcrire des tests pour l'interface utilisateur, y compris des tests de composants et des tests E2E (11 points)

#### [`Section 4: Mesurer l'efficacit√© des tests`](#section-4Ô∏è‚É£-measuring-test-effectiveness)

Surveiller le surveillant - mesurer la qualit√© des tests (4 points)

#### [`Section 5: Int√©gration continue`](#section-5Ô∏è‚É£-ci-and-other-quality-measures)

Lignes directrices pour l'int√©gration continue dans le monde du JS (9 points)

<br/><br/>

# Section 0Ô∏è‚É£: La r√®gle d'or

<br/>

## ‚ö™Ô∏è 0 La r√®gle d'or: Concevoir des tests minimalistes

:white_check_mark: **√Ä faire:**
Le code des tests n'est pas comme le code de production - con√ßoit le pour √™tre simple, court, sans abstraction, agr√©able √† utiliser et minimaliste. En regardant le code d'un test, on doit pouvoir comprendre son but instantan√©ment.

Nos esprits sont d√©j√† occup√©s avec le code de production, on n'a pas "d'espace" pour de la complexit√© additionnelle. Si on essaye d'ins√©rer un autre code compliqu√© dans nos pauvres cerveaux, l'√©quipe va √™tre ralentie ce qui est en contradiction avec la raison pour laquelle on fait des tests. 
En pratique, c'est l√† que de nombreuses √©quipes abandonnent tout simplement les tests.

Les tests sont une opportunit√© pour autre chose - un assistant amical et souriant, un avec qui il est agr√©able de travailler et qui nous apporte beaucoup pour peu d'investissement. La science nous dit que l'on a deux syst√®mes c√©r√©braux : le premier est utilis√© pour les activit√©s qui ne demandent pas d'effort comme conduire une voiture sur une route vide ; le deuxi√®me sert aux op√©rations complexes et conscientes comme r√©soudre une √©quation math√©matique. Con√ßois tes tests pour le premier syst√®me, lire un test doit _sembler_ aussi simple que de modifier un fichier HTML, et pas comme r√©soudre 2X(17 x 24).

On peut y arriver en s√©lectionnant des techniques, des outils et des cibles de tests qui sont rentables et offrent un bon retour sur investissement. Test seulement ce qui doit √™tre test√©, essaye de conserver de la souplesse, et parfois, il vaut m√™me mieux supprimer quelques tests et √©changer la fiabilit√© contre de l'agilit√© et de la simplicit√©.

![alt text](/assets/headspace.png "On a pas de place disponible pour une complexit√© suppl√©mentaire")

La plupart des conseils ci-dessous sont des d√©riv√©s de ce principe.

### Pr√™t √† commencer ?

<br/><br/>

# Section 1: Anatomie d'un test

<br/>

## ‚ö™ Ô∏è 1.1 Chaque nom devrait contenir 3 parties

:white_check_mark: **√Ä faire:** Un rapport de test devrait indiquer si la version actuelle de l'application correspond aux attentes pour des personnes qui ne sont pas forc√©ment famili√®res avec la base de code : le testeur, le dev ops qui d√©ploie et toi dans 2 ans. Dans ce but, les noms des tests doivent expliciter les attentes et inclure 3 parties :

(1) Qu'est-ce qui est test√© ? Par exemple, la m√©thode ProductService.addNewProduct

(2) Dans quelle circonstance et sc√©nario ? Par exemple, aucun prix n'est pass√© √† la m√©thode

(3) Quel est le r√©sultat attendu ? Par exemple, le produit n'est pas approuv√©

<br/>

‚ùå **Autrement:** Un d√©ploiement a √©chou√©, un test appel√© "Add product" √† √©chou√©. Est-ce que cela indique exactement ce qui ne fonctionne plus correctement ?

<br/>

**üëá Note:** Chaque point contient des exemples de codes et parfois une image d'illustration. Cliques pour agrandir.
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>
  
<br/>
  
### :clap: Bien faire les choses, exemple: Un nom de test constitu√© de 3 parties

![](https://img.shields.io/badge/üî®%20Example%20using%20Mocha-blue.svg "Using Mocha to illustrate the idea")

```javascript
//1. unit under test
describe('Products Service', function() {
  describe('Add new product', function() {
    //2. scenario and 3. expectation
    it('When no price is specified, then the product status is pending approval', ()=> {
      const newProduct = new ProductService().add(...);
      expect(newProduct.status).to.equal('pendingApproval');
    });
  });
});

```

<br/>

### :clap: Bien faire les choses, exemple: Un nom de test constitu√© de 3 parties

![alt text](/assets/bp-1-3-parts.jpeg "A test name that constitutes 3 parts")

</details>

<br/>
<details><summary>¬© <b>Credits & read-more</b></summary>
  1. <a href='https://osherove.com/blog/2005/4/3/naming-standards-for-unit-tests.html'>Roy Osherove - Naming standards for unit tests</a>
</details>

<br/><br/>

## ‚ö™ Ô∏è 1.2 Structurer les tests avec le pattern AAA

:white_check_mark: **√Ä faire:** Structure tes tests avec 3 sections s√©par√©es: Organiser, Agir & V√©rifier (Arrange, Act & Assert: AAA). Suivre cette structure garantit que le lecteur n'utilise pas de "CPU" de cerveau pour comprendre le plan du test :

1er A - Organiser (Arrange): Tout le code permettant de configurer le syst√®me selon le sc√©nario qui doit √™tre simul√©. Cela peut inclure d'instancier le constructeur de l'√©l√©ment test√©, ajouter des entr√©es en DB, mocking/stubbing des objets et autres codes de pr√©paration

2√®me A - Agir (Act): Ex√©cute l'√©l√©ment test√©. En g√©n√©ral 1 seule ligne de code

3√©me A - V√©rifier (Assert): V√©rifier que les valeurs re√ßues correspondent aux attentes. En g√©n√©ral 1 seule ligne de code

<br/>

‚ùå **Autrement:** Non seulement, vous avez pass√© des heures √† comprendre le code principal, mais en plus ce qui devait √™tre la partie la plus simple de la journ√©e (tester) vous tord le cerveau.


<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Un test structur√© avec le pattern AAA

![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest") ![](https://img.shields.io/badge/üîß%20Example%20using%20Mocha-blue.svg "Examples with Mocha")

```javascript
describe("Customer classifier", () => {
  test("When customer spent more than 500$, should be classified as premium", () => {
    //Arrange
    const customerToClassify = { spent: 505, joined: new Date(), id: 1 };
    const DBStub = sinon.stub(dataAccess, "getCustomer").reply({ id: 1, classification: "regular" });

    //Act
    const receivedClassification = customerClassifier.classifyCustomer(customerToClassify);

    //Assert
    expect(receivedClassification).toMatch("premium");
  });
});
```

<br/>

### :thumbsdown: Exemple d'anti pattern: Pas de s√©paration, un bloc, plus dur √† interpr√©ter

```javascript
test("Should be classified as premium", () => {
  const customerToClassify = { spent: 505, joined: new Date(), id: 1 };
  const DBStub = sinon.stub(dataAccess, "getCustomer").reply({ id: 1, classification: "regular" });
  const receivedClassification = customerClassifier.classifyCustomer(customerToClassify);
  expect(receivedClassification).toMatch("premium");
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è1.3 D√©crire les attentes dans un language produit: Utiliser des assertions de type BDD

:white_check_mark: **√Ä faire:** Coder tes tests dans un langage d√©claratif permet au lecteur de comprendre imm√©diatement sans effectuer un seul cycle de "CPU" de cerveau. Lorsque tu √©cris du code imp√©ratif remplis de logique conditionnelles, le lecteur est forc√© d'utiliser plus de cycles de "CPU" de cerveau. Dans ce cas, code les attentes dans un langage similaire au langage humain, dans un style d√©claratif de type BDD avec `expect` ou `should` et sans utiliser de code custom. Si Chai et Jest n'incluent pas les assertions n√©cessaires et qu'elles reviennent r√©guli√®rement, consid√®re [d'√©tendre Jest matcher (Jest)](https://jestjs.io/docs/en/expect#expectextendmatchers) ou d'√©crire un [plugin Chai custom](https://www.chaijs.com/guide/plugins/)

<br/>

‚ùå **Autrement:** L'√©quipe √©crira moins de tests et d√©corera ceux qui sont ennuyeux avec .skip()

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary><br/>

![](https://img.shields.io/badge/üîß%20Example%20using%20Mocha-blue.svg "Examples with Mocha & Chai") ![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest")

### :thumbsdown: Exemple d'anti pattern: Le lecteur doit parcourir un long code imp√©ratif juste pour comprendre l'histoire du test

```javascript
test("When asking for an admin, ensure only ordered admins in results", () => {
  //assuming we've added here two admins "admin1", "admin2" and "user1"
  const allAdmins = getUsers({ adminOnly: true });

  let admin1Found,
    adming2Found = false;

  allAdmins.forEach(aSingleUser => {
    if (aSingleUser === "user1") {
      assert.notEqual(aSingleUser, "user1", "A user was found and not admin");
    }
    if (aSingleUser === "admin1") {
      admin1Found = true;
    }
    if (aSingleUser === "admin2") {
      admin2Found = true;
    }
  });

  if (!admin1Found || !admin2Found) {
    throw new Error("Not all admins were returned");
  }
});
```

<br/>

### :clap: Bien faire les choses, exemple: Parcourir le test d√©claratif suivant est un jeu d'enfant

```javascript
it("When asking for an admin, ensure only ordered admins in results", () => {
  //assuming we've added here two admins
  const allAdmins = getUsers({ adminOnly: true });

  expect(allAdmins)
    .to.include.ordered.members(["admin1", "admin2"])
    .but.not.include.ordered.members(["user1"]);
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è 1.4 S'en tenir aux tests des boites noires : Ne tester que les m√©thodes publiques

:white_check_mark: **√Ä faire:** Tester les composants internes apporte beaucoup de complexit√© pour presque rien. Si ton code/API d√©livre les bon r√©sultats, est-ce que tu dois vraiment passer les 3 prochaines heures √† tester COMMENT il fonctionne et maintenir ces tests ? √Ä chaque fois qu'un comportement publique est test√©, l'impl√©mentation priv√©e est aussi test√© implicitement, et test tests n'√©choueront que si il y a un certain probl√®me (par exemple: mauvais retour). Cette approche est aussi appel√©e `behavioral testing` (test de comportement). De l'autre c√¥t√©, si tu dois tester les √©l√©ments internes (approche de la bo√Æte blanche) - l'objectif passe de planifier le r√©sultat du composant √† des d√©tails de bases, et votre test peut √©chouer √† cause de refactoring mineurs alors que le r√©sultat est toujours bon - cela augmente la charge de maintenance.
<br/>

‚ùå **Autrement:** Tes tests se comportent comme [l'enfant qui criait au loup](https://fr.wikipedia.org/wiki/L%27Enfant_qui_criait_au_loup): crier des faux positifs (par exemple, un test √©choue parce qu'un nom de variable priv√© a √©t√© chang√©). Sans surprise, les gens vont rapidement ignorer les notifications, jusqu'√† ce qu'un jour, un vrai bug soit ignor√©

<br/>
<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Un cas qui test une m√©thode interne sans raison valable

![](https://img.shields.io/badge/üîß%20Example%20using%20Mocha-blue.svg "Examples with Mocha & Chai")

```javascript
class ProductService {
  //this method is only used internally
  //Change this name will make the tests fail
  calculateVATAdd(priceWithoutVAT) {
    return { finalPrice: priceWithoutVAT * 1.2 };
    //Change the result format or key name above will make the tests fail
  }
  //public method
  getPrice(productId) {
    const desiredProduct = DB.getProduct(productId);
    finalPrice = this.calculateVATAdd(desiredProduct.price).finalPrice;
    return finalPrice;
  }
}

it("White-box test: When the internal methods get 0 vat, it return 0 response", async () => {
  //There's no requirement to allow users to calculate the VAT, only show the final price. Nevertheless we falsely insist here to test the class internals
  expect(new ProductService().calculateVATAdd(0).finalPrice).to.equal(0);
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è Ô∏è1.5 Choisir les bons "test doubles": √âviter les mocks en faveur des stubs et spies

:white_check_mark: **√Ä faire:** Les "test doubles" sont un mal n√©cessaire parce qu'ils sont coupl√©s aux composants internes mais apportent n√©anmoins beaucoup de valeur (<a href="https://martinfowler.com/articles/mocksArentStubs.html" data-href="https://martinfowler.com/articles/mocksArentStubs.html" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">[Retrouve ici un rappel √† propos des "test doubles": mocks vs stubs vs spies](https://martinfowler.com/articles/mocksArentStubs.html)</a>).

Avant d'utiliser des "test doubles", pose toi une question tr√®s simple: Est-ce que je l'utilise pour tester une fonctionnalit√© qui appara√Æt, ou peut appara√Ætre, dans le document de sp√©cification ? Si non, √ßa sent le test de boite blanche.

Par exemple, si tu veux tester que ton application se comporte correctement quand le service de paiement est coup√©, tu peux faire un stub du service de paiement et d√©clencher une r√©ponse de type 'No Response' pour v√©rifier que l'unit√© test√©e retourne la bonne valeur. Cela v√©rifie le comportement/r√©ponse de notre application suivant un certain sc√©nario. Tu peux aussi utiliser un spy pour v√©rifier qu'un email a bien √©t√© envoy√© quand ce service √©tait coup√© - il s'agit encore une fois d'un test de comportement qui pourrait appara√Ætre dans les sp√©cifications ("Envoyer un email si le paiement n'as pas pu √™tre enregistr√©"). 
D'un autre c√¥t√©, si tu mock le service de paiement pour v√©rifier qu'il a bien √©t√© appel√© avec le bon type Javascript, alors ton test est orient√© sur des comportements internes qui n'ont rien √† voir avec les fonctionnalit√©s de l'application et changeront probablement fr√©quemment.
<br/>

‚ùå **Autrement:** Chaque refactoring du code implique de chercher l'ensemble des mock dans le code afin de les mettre √† jour. Les tests deviennent une corv√©e plut√¥t qu'un ami aidant.
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Les mocks se concentrent sur des composants internes

![](https://img.shields.io/badge/üîß%20Example%20using%20Sinon-blue.svg "Examples with Sinon")

```javascript
it("When a valid product is about to be deleted, ensure data access DAL was called once, with the right product and right config", async () => {
  //Assume we already added a product
  const dataAccessMock = sinon.mock(DAL);
  //hmmm BAD: testing the internals is actually our main goal here, not just a side-effect
  dataAccessMock
    .expects("deleteProduct")
    .once()
    .withArgs(DBConfig, theProductWeJustAdded, true, false);
  new ProductService().deletePrice(theProductWeJustAdded);
  dataAccessMock.verify();
});
```

<br/>

### :clap: Bien faire les choses, exemple : Les spies se concentrent sur les fonctionnalit√©s requises mais touchent les composants internes par effet de bord

```javascript
it("When a valid product is about to be deleted, ensure an email is sent", async () => {
  //Assume we already added here a product
  const spy = sinon.spy(Emailer.prototype, "sendEmail");
  new ProductService().deletePrice(theProductWeJustAdded);
  //hmmm OK: we deal with internals? Yes, but as a side effect of testing the requirements (sending an email)
  expect(spy.calledOnce).to.be.true;
});
```

</details>

<br/><br/>

## üìó Envie d'apprendre ces bonnes pratiques en vid√©o ?

### Va voir mon cours en ligne [Testing Node.js & JavaScript From A To Z](https://www.testjavascript.com)

<br/><br/>

## ‚ö™ Ô∏è1.6 Utiliser des donn√©es r√©alistes

:white_check_mark: **√Ä faire:** Souvent les bugs de production sont r√©v√©l√©s par des entr√©es tr√®s sp√©cifiques et surprenantes. Plus les entr√©es de tests seront r√©alistes, plus il y a de chance de d√©tecter les bugs t√¥t. Utilise une librairie d√©di√©e comme [Faker](https://www.npmjs.com/package/faker) pour g√©n√©rer des pseudo-vrais donn√©es qui ressemble aux donn√©es de production. Par exemple, ce type de librairie peut g√©n√©rer de fa√ßon r√©aliste des num√©ros de t√©l√©phone, noms d'utilisateur, cartes de cr√©dit, nom de soci√©t√© et m√™me du 'Lorem ipsum'. Tu peux aussi cr√©er des tests (en plus des tests unitaires, par √† leur place) qui utilise des fausses donn√©es randomis√©es pour pousser test tests, ou m√™me importer de vraies donn√©es depuis ton environnement de production. Envie de passer au niveau sup√©rieur ? Regarde le prochain point (property-based testing).
<br/>

‚ùå **Autrement:** Tout vos tests de d√©veloppement vont montrer du vert √† tort avec des entr√©es tels que "Foo", mais en production ils passeront au rouge lorsqu'un hacker passera une chaine de caract√®re tel que ‚Äú@3e2ddsf . ##‚Äô 1 fdsfds . fds432 AAAA‚Äù
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Une suite de test qui passe √† cause de donn√©es non r√©alistes
![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest")

```javascript
const addProduct = (name, price) => {
  const productNameRegexNoSpace = /^\S*$/; //no white-space allowed

  if (!productNameRegexNoSpace.test(name)) return false; //this path never reached due to dull input

  //some logic here
  return true;
};

test("Wrong: When adding new product with valid properties, get successful confirmation", async () => {
  //The string "Foo" which is used in all tests never triggers a false result
  const addProductResult = addProduct("Foo", 5);
  expect(addProductResult).toBe(true);
  //Positive-false: the operation succeeded because we never tried with long
  //product name including spaces
});
```

<br/>

### :clap: Bien faire les choses, exemple : Donn√©es r√©alistes randomis√©s

```javascript
it("Better: When adding new valid product, get successful confirmation", async () => {
  const addProductResult = addProduct(faker.commerce.productName(), faker.random.number());
  //Generated random input: {'Sleek Cotton Computer',  85481}
  expect(addProductResult).to.be.true;
  //Test failed, the random input triggered some path we never planned for.
  //We discovered a bug early!
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è 1.7 Tester plusieurs combinaisons d'input avec le Property-based testing

:white_check_mark: **√Ä faire:** En r√®gle g√©n√©ral, on choisit quelques valeurs d'entr√©es pour chaque test. M√™me lorsque le format des inputs est r√©aliste (voir le point 'Utiliser des donn√©es r√©alistes'), on couvre seulement quelques combinaisons d'entr√©es. En revanche, en production, une API appel√©e avec 5 param√®tres peut √™tre invoqu√©e avec des milliers de permutations diff√©rentes, l'une d'entre elle peut faire √©chouer notre processus ([voir le Fuzz testing](https://fr.wikipedia.org/wiki/Fuzzing)). Et si tu pouvais √©crire un seul test qui envoie 1000 permutations d'entr√©es automatiquement et d√©tecte pour lequel d'entre eux notre processus ne retourne pas la bonne valeur ? Le Property-based testing c'est une m√©thode qui fait exactement √ßa : En testant toutes les combinaisons d'entr√©es possible on augmente les chance de d√©tecter un bug. Par exemple, prenons une m√©thode : addNewProduct(id, name, isDiscount), la librairie appellera cette m√©thode avec plusieurs combinaisons de (number, string, boolean) tel que (1, ‚ÄúiPhone‚Äù, false), (2, ‚ÄúGalaxy‚Äù, true). Tu peux utiliser le property-based testing avec ta librairie de test pr√©f√©r√© (Mocha, Jest ...etc) √† l'aide de librairie tel que [js-verify](https://github.com/jsverify/jsverify) ou [testcheck](https://github.com/leebyron/testcheck-js) (meilleure documentation). MAJ: Nicolas Dubien √† sugg√©r√© dans les commentaire de [regarder fast-check](https://github.com/dubzzz/fast-check#readme) qui semble offrir des fonctionnalit√©es suppl√©mentaire et √™tre activement maintenue.
<br/>

‚ùå **Autrement:** Inconsciemment, tu choisis des entr√©es de test qui ne couvrent que les cas qui fonctionnent correctement. Malheureusement, cela r√©duit l'efficacit√© tests et leur capacit√© a d√©tecter des bugs.
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Tester plusieurs permutations d'entr√©es avec "fast-check"

![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest")

```javascript
import fc from "fast-check";

describe("Product service", () => {
  describe("Adding new", () => {
    //this will run 100 times with different random properties
    it("Add new product with random yet valid properties, always successful", () =>
      fc.assert(
        fc.property(fc.integer(), fc.string(), (id, name) => {
          expect(addNewProduct(id, name).status).toEqual("approved");
        })
      ));
  });
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è 1.8 Si besoin, n'utiliser que des snapshots courts et inline

:white_check_mark: **Do:** Quand il y a un besoin pour du [snapshot testing](https://jestjs.io/docs/en/snapshot-testing), utilise seulement des snapshots courts (3-7 lignes) qui sont inclut dans le test ([Inline Snapshot](https://jestjs.io/docs/en/snapshot-testing#inline-snapshots)) et pas dans des fichiers externes. Respecter cette r√®gle permettra √† vos tests de rester auto-explicatif et moins fragile.

D'un autre c√¥t√©, les tutoriels et outils 'classique' encouragent √† stocker de gros fichiers (r√©sultats d'API JSON, markup d'un composant) sur un emplacement externe et de s'assurer √† chaque fois que le test est lanc√©, de comparer le r√©sultat re√ßu avec la version sauvegard√©e. Cela peut, par exemple, implicitement coupler notre test √† 1000 lignes avec 3000 valeurs que le lecteur du test ne verra jamais et auquel il ne pensera pas. Pourquoi est-ce que c'est mauvais ? En faisant √ßa, il y a 1000 raisons pour votre test d'√©chouer - Il suffit qu'une seule ligne change pour que le snapshot soit invalide, et cela arrivera probablement souvent. √Ä quelle fr√©quence ? Pour chaque espace, commentaire ou changement mineur dans le HTML/CSS. De plus, le nom du test ne donnera pas la moindre indication √† propos de l'erreur vu qu'il v√©rifie simplement que les 1000 lignes n'ont pas chang√©. Cela encourage aussi celui qui √©crit les tests √† accepter comme valeur de succ√®s un long document qu'il ne pourra pas inspecter et v√©rifier. Tous ces points sont des sympt√¥mes d'un test obscure qui n'est pas cibl√© et cherche √† en faire trop.

Il faut noter qu'il y a quelques cas ou de long snapshots externes sont acceptable - Pour valider un sch√©ma et pas des donn√©es ou concernant des documents qui ne changent presque jamais
<br/>

‚ùå **Sinon:** Un test UI √©choue. Le code semble bon, l'√©cran rend parfaitement les pixels, que s'est-il pass√© ? Ton test de snapshot a trouv√© une diff√©rence entre le document original et le document actuel - un simple espace a √©t√© ajout√© dans le markdown...

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Coupler nos tests √† 2000 lignes de code qu'on ne voit pas

![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest")

```javascript
it("TestJavaScript.com is renderd correctly", () => {
  //Arrange

  //Act
  const receivedPage = renderer
    .create(<DisplayPage page="http://www.testjavascript.com"> Test JavaScript </DisplayPage>)
    .toJSON();

  //Assert
  expect(receivedPage).toMatchSnapshot();
  //We now implicitly maintain a 2000 lines long document
  //every additional line break or comment - will break this test
});
```

<br/>

### :clap: Bien faire les choses, exemple: Les attentes sont claires et sp√©cifiques

```javascript
it("When visiting TestJavaScript.com home page, a menu is displayed", () => {
  //Arrange

  //Act
  const receivedPage = renderer
    .create(<DisplayPage page="http://www.testjavascript.com"> Test JavaScript </DisplayPage>)
    .toJSON();

  //Assert

  const menu = receivedPage.content.menu;
  expect(menu).toMatchInlineSnapshot(`
<ul>
<li>Home</li>
<li> About </li>
<li> Contact </li>
</ul>
`);
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è1.9 √âviter les fixtures et seeds globals, ajouter les donn√©es par test

:white_check_mark: **√Ä faire:** En suivant la r√®gle d'or (point 0), chaque test doit ajouter et agir sur son propre jeu d'entr√©e en base de donn√©es pour √©viter d'√™tre coupl√©s et faciliter le raisonnement √† propos de la logique du test. En r√©alit√©, cette r√®gle est souvent viol√©e par les testeurs qui remplissent la base de donn√©es avant de lancer les tests ([aussi connu sous le nom ‚Äòtest fixture‚Äô](https://en.wikipedia.org/wiki/Test_fixture)) afin d'am√©liorer les performances. M√™me si la performance est effectivement une inqui√©tude valide, elle peut √™tre att√©nu√©e (voir "Component testing"), en revanche, la complexit√© des tests est une peine bien plus douloureuse qui devrait r√©gir les autres consid√©rations la plupart du temps.
En pratique, chaque cas test√© doit explicitement ajouter les entr√©es en base de donn√©es dont il a besoin et n'agir que sur ces entr√©es. Si la performance devient une inqui√©tude critique - un compromis peut se trouver sous la forme de seeds pour les jeux de tests qui ne modifient pas les donn√©es (queries).

<br/>

‚ùå **Autrement:** Certains tests √©choue, le d√©ploiement est annul√©, l'√©quipe va d√©penser un temps pr√©cieux maintenant, est-ce qu'on a un bug ? Investiguons, oh non - il semble que deux tests modifiaient les m√™me donn√©es

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: les tests ne sont pas ind√©pendants et reposent sur un hook global pour des donn√©es globales en DB

![](https://img.shields.io/badge/üîß%20Example%20using%20Mocha-blue.svg "Examples with Mocha")

```javascript
before(async () => {
  //adding sites and admins data to our DB. Where is the data? outside. At some external json or migration framework
  await DB.AddSeedDataFromJson('seed.json');
});
it("When updating site name, get successful confirmation", async () => {
  //I know that site name "portal" exists - I saw it in the seed files
  const siteToUpdate = await SiteService.getSiteByName("Portal");
  const updateNameResult = await SiteService.changeName(siteToUpdate, "newName");
  expect(updateNameResult).to.be(true);
});
it("When querying by site name, get the right site", async () => {
  //I know that site name "portal" exists - I saw it in the seed files
  const siteToCheck = await SiteService.getSiteByName("Portal");
  expect(siteToCheck.name).to.be.equal("Portal"); //Failure! The previous test change the name :[
});

```

<br/>

### :clap: Bien faire les choses, exemple: On peut rester dans le test, chaque test agis sur ses propres donn√©es

```javascript
it("When updating site name, get successful confirmation", async () => {
  //test is adding a fresh new records and acting on the records only
  const siteUnderTest = await SiteService.addSite({
    name: "siteForUpdateTest"
  });

  const updateNameResult = await SiteService.changeName(siteUnderTest, "newName");

  expect(updateNameResult).to.be(true);
});
```

</details>

<br/>

## ‚ö™ Ô∏è 1.10 Ne pas catcher les erreurs, les pr√©voir

:white_check_mark: **√Ä faire:** Lorsqu'on essaye de d√©tecter que certaines entr√©es d√©clenchent une erreur, il peut sembler √™tre une bonne id√©e d'utiliser try-catch-finally et de v√©rifier qu'on est pass√© dans le catch. Le r√©sultat est un test √©trange et verbeux (exemple plus bas) qui cache l'intention simple du test et le r√©sultat attendu.

Une alternative plus √©l√©gante est d'utiliser l'assertion Chai d√©di√©e : expect(method).to.throw (ou en Jest: expect(method).toThrow()). Il est √©galement obligatoire de v√©rifier que l'exception contient une propri√©t√© qui indique le type d'erreur, sinon, en recevant un message d'erreur g√©n√©rique, l'application ne sera pas capable de faire beaucoup plus que de montrer un message d√©cevant √† l'utilisateur.
<br/>

‚ùå **Autrement:** Il sera compliqu√© de d√©duire du rapport de test ce qui s'est mal pass√©

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Un long test qui essaye de v√©rifier la pr√©sence d'une erreur avec try-catch

![](https://img.shields.io/badge/üîß%20Example%20using%20Mocha-blue.svg "Examples with Mocha")

```javascript
it("When no product name, it throws error 400", async () => {
  let errorWeExceptFor = null;
  try {
    const result = await addNewProduct({});
  } catch (error) {
    expect(error.code).to.equal("InvalidInput");
    errorWeExceptFor = error;
  }
  expect(errorWeExceptFor).not.to.be.null;
  //if this assertion fails, the tests results/reports will only show
  //that some value is null, there won't be a word about a missing Exception
});
```

<br/>

### :clap: Bien faire les choses, exemple: Un attente lisible qui peut √™tre comprise simplement, peut √™tre m√™me par un QA ou PM technique

```javascript
it("When no product name, it throws error 400", async () => {
  await expect(addNewProduct({}))
    .to.eventually.throw(AppError)
    .with.property("code", "InvalidInput");
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è 1.11 Taguer tes tests

:white_check_mark: **√Ä faire:** Des tests diff√©rents doivent √™tre lanc√©s dans diff√©rents sc√©narios. Les tests de fum√©e (quick smoke), IO-less, doivent tourner √† chaque fois qu'un d√©veloppeur sauvegarde ou commit un fichier, les tests complets end-to-end sont en g√©n√©ral lanc√©s quand une nouvelle pull-request est soumise, etc.
On peut r√©aliser √ßa en taggant les tests avec des mots clefs comme #cold #api #sanity pour pouvoir utiliser grep et s√©lectionner les tests qui nous interesse. Par exemple, voil√† comment invoquer uniquement le groupe de test 'sanity' avec Mocha : mocha - grep 'sanity'
<br/>

‚ùå **Autrement:** Lancer tous les tests, y compris ceux qui ex√©cutent des dizaines de requ√™tes DB, √† chaque fois qu'un d√©veloppeur fait un petit changement peut √™tre extr√™mement lent et pousser les d√©veloppeurs a ne pas utiliser les tests.
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Taguer des tests avec '#cold-test' permet √† celui qui les lance de n'executer que les tests rapide (cold = tests rapides qui ne font pas d'op√©rations IO et peuvent √™tre execut√©s souvent, meme pendant que le d√©veloppeur code)

![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest")

```javascript
//this test is fast (no DB) and we're tagging it correspondigly
//now the user/CI can run it frequently
describe("Order service", function() {
  describe("Add new order #cold-test #sanity", function() {
    test("Scenario - no currency was supplied. Expectation - Use the default currency #sanity", function() {
      //code logic here
    });
  });
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è 1.12 Cat√©goriser tes tests sous au moins 2 niveaux

:white_check_mark: **√Ä faire:** Applique une structure √† ta suite de tests pour qu'un visiteur occasionnel puisse facilement comprendre les attentes (Les tests sont la meilleure documentation) et les diff√©rents sc√©narios test√©s. Une m√©thode fr√©quence pour √ßa est de placer au moins 2 blocs 'describe' au-dessus de vos tests : Le premier est pour le nom de l'unit√© test√© et le deuxi√®me pour un niveau suppl√©mentaire de cat√©gorisation comme le sc√©nario ou une cat√©gorie (voir l'exemple de code plus bas). Cette organisation am√©liorera grandement vos rapports de tests: Le lecteur comprendra simplement les cat√©gories de tests, examinera la section voulue et verra les corr√©lations entre les tests qui √©chouent. De plus, ce sera bien plus simple pour un d√©veloppeur de naviguer dans le code d'une suite avec de nombreux tests. Il y a plusieurs structures alternatives pour les suites de tests que tu peux envisager comme [given-when-then](https://github.com/searls/jasmine-given) et [RITE](https://github.com/ericelliott/riteway)

<br/>

‚ùå **Autrement:** En regardant un rapport avec une longue liste de tests a plat, le lecteur devra lire un long texte pour comprendre les sc√©narios majeurs et comprendre les liens entre les tests qui √©chouent. Imagine le cas suivant : Quand 7/100 tests √©chouent, regarder une liste √† plat n√©cessitera d'aller lire le contenu des tests qui √©chouent pour comprendre le lien entre eux. En revanche, dans un rapport hi√©rarchique, ils pourraient tous √™tre au sein du m√™me sc√©nario ou d'une cat√©gorie et le lecteur pourra rapidement d√©duire ce qui est, ou du moins o√π est, la cause de l'erreur.

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Structurer une suite avec le nom de l'unit√© test√© et les sc√©narios m√®nera au rapport pratique montr√© ci-dessous
![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest")

```javascript
// Unit under test
describe("Transfer service", () => {
  //Scenario
  describe("When no credit", () => {
    //Expectation
    test("Then the response status should decline", () => {});

    //Expectation
    test("Then it should send email to admin", () => {});
  });
});
```

![alt text](assets/hierarchical-report.png)

<br/>

### :thumbsdown: Exemple d'anti-pattern: Une liste de tests √† plat qui rend l'identification du probl√®me difficile pour le lecteur

![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Mocha")

```javascript
test("Then the response status should decline", () => {});

test("Then it should send email", () => {});

test("Then there should not be a new transfer record", () => {});
```

![alt text](assets/flat-report.png)

<br/>

</details>

<br/><br/>

## ‚ö™ Ô∏è1.13 Autre bonnes pratiques g√©n√©riques

:white_check_mark: **√Ä faire:** Ce post se concentre sur des conseils de tests qui sont en rapport, ou au moins peuvent √™tre pr√©sent√©s, avec Node JS. Ce point, cependant, regroupe quelques conseils sans rapport avec Node qui sont bien connus.

Apprends et pratique [les principes TDD](https://www.sm-cloud.com/book-review-test-driven-development-by-example-a-tldr/) - ils ont beaucoup de valeurs pour la plupart, mais ne soit pas intimid√©s s'ils ne correspondent pas √† ton style, tu n'es pas le seul. Envisage d'√©crire les tests avec le code dans un [red-green-refactor style](https://blog.cleancoder.com/uncle-bob/2014/12/17/TheCyclesOfTDD.html), v√©rifie que chaque test v√©rifie exactement une chose, quand tu trouves un bug - avant de le fixer, √©crit un test qui d√©tectera le bug √† l'avenir, laisse chaque test √©chouer au moins une fois avant de devenir vert, commence un module en √©crivant du code simple et rapide qui valide le test - puis refactor graduellement et passe le code a un niveau de production, √©vite toute d√©pendance √† l'environnement (paths, OS, etc)
<br/>

‚ùå **Autrement:** Tu manqueras les perles de sagesses recueillies pendant des d√©cennies.

<br/><br/>

# Section 2Ô∏è‚É£: Tests Backend

## ‚ö™ Ô∏è2.1 Enrichis ton portefeuille de test: Vois plus loin que les tests unitaire et la pyramide

:white_check_mark: **√Ä faire:** La [pyramide de tests](https://martinfowler.com/bliki/TestPyramid.html), bien que vielle de plus de 10 ans, est un bon mod√®le qui sugg√®re trois types de tests et influence la plupart des strat√©gies de tests des d√©veloppeurs. Dans un m√™me temps, une poign√©e de nouvelles techniques de tests brillantes ont √©merg√© et sont dans l'ombre de la pyramide de tests. √âtant donn√© l'√©tendu des changements que l'on a vu ces 10 derni√®res ann√©es (micro-services, cloud, serverless), est-il seulement possible qu'un vieux mod√®le soit adapt√© √† *tout* les types d'applications ? Le monde du test ne devrait-il pas accueillir de nouvelles techniques ?

Ne vous m√©prenez pas, en 2019, la pyramide de tests, le TDD et les tests unitaires sont toujours une technique puissante et sont probablement le meilleur choix pour beaucoup d'applications. Seulement, comme les autres mod√®les, malgr√© qu'il soit utile, [il doit √™tre faux parfois](https://en.wikipedia.org/wiki/All_models_are_wrong). Par exemple, imagine une application IoT qui traite de nombreux √©v√©nements dans une queue (message-bus) comme Kafka/RabbitMQ, qui vont ensuite dans un entrepot de donn√©e puis sont lus par une UI d'analyse. Est-ce qu'on devrait vraiment d√©penser 50% de notre budget de test pour √©crire des tests unitaires sur une application qui est centr√©e sur l'int√©gration et n'a presque aucune logique ? Plus la diversit√© des applications augmente (bots, crypto, Alexa-skills) plus les chances sont grandes de trouver un sc√©nario ou la pyramide de test n'est pas le meilleur choix.

Il est temps d'enrichir ton portefeuille de test et de devenir familier avec plus de types de tests (les prochains points sugg√®rent quelques id√©es), des mod√®les tels que celui de la pyramide de tests mais aussi d'associer les types de tests aux probl√®mes que tu rencontres dans le monde r√©el ('Hey, notre API est cass√©, √©crivons des consumer-driven contract testing!'), diversifie tes tests comme un investisseur qui construit son portefeuille en se basant sur l'analyse des risques - estime o√π les probl√®mes risquent de se poser et applique des mesures de pr√©vention pour r√©duire ces risques.

Un mot d'avertissement: l'argument du TDD dans le monde du d√©veloppement √† un visage typique de fausse dichotomie, certains disent de l'utiliser de partout, d'autres pensent que c'est le diable. Tous ceux qui parlent en absolu ont tord :]

<br/>

‚ùå **Autrement:** Tu va rater des outils avec un retour sur investissement incroyable, certains comme Fuzz, lint, ou mutation peuvent apporter de la valeur en 10 minutes

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Cindy Sridharan propose un portefeuille de tests riche dans son excellent post 'Testing Microservices - the same way'

![alt text](assets/bp-12-rich-testing.jpeg "Cindy Sridharan suggests a rich testing portfolio in her amazing post ‚ÄòTesting Microservices‚Ää‚Äî‚Ääthe sane way‚Äô")

<strong class="markup--strong markup--p-strong">‚ò∫Ô∏èExample: </strong><a href="https://www.youtube.com/watch?v=-2zP494wdUY&amp;feature=youtube" data-href="https://www.youtube.com/watch?v=-2zP494wdUY&amp;feature=youtu.be" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">[YouTube: ‚ÄúBeyond Unit Tests: 5 Shiny Node.JS Test Types (2018)‚Äù (Yoni Goldberg)](https://www.youtube.com/watch?v=-2zP494wdUY&feature=youtu.be)</a>

<br/>

![alt text](assets/bp-12-Yoni-Goldberg-Testing.jpeg "A test name that constitutes 3 parts")

</details>

<br/><br/>

## ‚ö™ Ô∏è2.2 Les tests de composant pourrait √™tre ton meilleur arrangement

:white_check_mark: **√Ä faire:** Chaque test unitaire couvre une petite portion de l'application et il est co√ªteux de couvrir l'ensemble, alors que les tests end-to-end couvrent facilement une grande partie mais sont lent, pourquoi ne pas appliquer une approche interm√©diaire et √©crire des tests qui sont plus gros que les tests unitaires mais plus petits que les tests end-to-end ? Les tests de composant (Component testing) sont m√©connus du monde de test mais ils offrent le meilleur des deux mondes: des performances raisonnable et la possibilit√© d'appliquer le pattern TDD + une couverture correcte et r√©aliste

Les tests de composant se concentrent sur "l'unit√©" du microservice, ils fonctionnent sur l'API, ne mock rien qui appartient au microservice lui-m√™me (une vrai DB, ou au moins une version in-memory de cette DB) mais stub tout ce qui est externe, comme les appels √† d'autres microservices. En faisant √ßa, on test ce que l'on d√©ploie, on approche l'application de l'ext√©rieur vers l'int√©rieur et on gagne en confiance dans un laps de temps raisonnable.

<br/>

‚ùå **Autrement:** Tu risque de passer de longues journ√©e √† √©crire des tests unitaire pour te rendre compte que tu n'as que 20% de couverture

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Supertest permet d'approcher l'API Express (rapide et couvre plusieurs niveaux)

![](https://img.shields.io/badge/üîß%20Example%20using%20Mocha-blue.svg "Examples with Mocha")

![alt text](assets/bp-13-component-test-yoni-goldberg.png " [Supertest](https://www.npmjs.com/package/supertest) allows approaching Express API in-process (fast and cover many layers)")

</details>

<br/><br/>

## ‚ö™ Ô∏è2.3 V√©rifier que les nouvelles versions ne cassent pas l'API avec les tests de contrat

:white_check_mark: **√Ä faire:** Ton microservice a plusieurs clients, et tu ex√©cutes plusieurs versions du service pour des raisons de compatibilit√© (pour que tout le monde soit content). Puis tu changes un champ et 'boom!', un client important qui compte sur ce champ est en col√®re. C'est le Catch-22 du monde de l'int√©gration : Il est tr√®s difficile pour le cot√© serveur de consid√©rer toutes les attentes des clients. D'un autre cot√©, les clients ne peuvent pas r√©aliser de tests puisque le serveur contr√¥les les dates de sorties. [Les "consumer-driven contracts" et le framework PACT](https://docs.pact.io) sont n√©s pour formaliser ce processus avec une approche disruptive - ce n'est pas le serveur qui d√©finit ses propres plans de test, mais le client qui d√©finit les tests du ...serveur! PACT peut enregistrer les attentes du client et les placer dans un emplacement partag√©, "broker", afin que le serveur puisse extraire les attentes et s'ex√©cuter sur chaque version en utilisant la librairie PACT pour d√©tecter les contrats rompus - une attente du client qui n'est pas satisfaite. En faisant √ßa, toutes les incompatibilit√©s d'API server-client sont rep√©r√©s t√¥t pendant le build/CI et peuvent vous √©viter beaucoup de frustration.
<br/>

‚ùå **Autrement:** L'alternative sont les tests manuels √©puisants ou la peur du d√©ploiement
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple:

![](https://img.shields.io/badge/üîß%20Example%20using%20PACT-blue.svg "Examples with PACT")

![alt text](assets/bp-14-testing-best-practices-contract-flow.png)

</details>

<br/><br/>

## ‚ö™ Ô∏è 2.4 Tester tes middlewares de mani√®re isol√©e

:white_check_mark: **√Ä faire:** Beaucoup √©vitent les tests de Middleware parce qu'ils repr√©sentent une petite portion du syst√®me et requi√®rent un serveur express live. Ce sont deux mauvaises raisons - les Middlewares sont petits, mais affectent toute ou la plupart des requ√™tes et peuvent √™tre test√©s simplement en tant que fonction qui re√ßoit un objet JS {req,res}. Pour tester un middleware, il suffit de l'invoquer et d'espionner ([avec Sinon par exemple](https://www.npmjs.com/package/sinon) l'interaction avec l'objet {req,res} pour s'assurer que la fonction a effectu√©e la bonne action. La librairie [node-mock-http](https://www.npmjs.com/package/node-mocks-http) va encore plus loin et prend en compte l'objet {req,res} tout en surveillant son comportement. Par exemple, il peut v√©rifier que le status http qui √† √©t√© d√©fini sur l'objet res correspond aux attentes (voir l'exemple ci-dessous)
<br/>

‚ùå **Autrement:** Un bug dans un middleware Express === un bug dans toutes ou la plupart des requ√™tes
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Tester le middleware en isolation sans effectuer d'appel r√©seau et sans r√©veiller l'ensemble de la machine Express

![](https://img.shields.io/badge/üîß%20Example%20using%20Jest-blue.svg "Examples with Jest")

```javascript
//the middleware we want to test
const unitUnderTest = require("./middleware");
const httpMocks = require("node-mocks-http");
//Jest syntax, equivelant to describe() & it() in Mocha
test("A request without authentication header, should return http status 403", () => {
  const request = httpMocks.createRequest({
    method: "GET",
    url: "/user/42",
    headers: {
      authentication: ""
    }
  });
  const response = httpMocks.createResponse();
  unitUnderTest(request, response);
  expect(response.statusCode).toBe(403);
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è2.5 Mesurer et refactoriser en utilisant des outils d'analyse statique

:white_check_mark: **√Ä faire:** Utiliser des outils d'analyse statique donne des moyens objectif d'am√©liorer la qualit√© et de garder le code maintenable. Tu peux ajouter un outil d'analyse statique √† ton build CI pour l'annuler si il d√©tecte un "code smell". Ses arguments de vente par rapport au linting simple sont la capacit√© d'inspecter la qualit√© dans le contexte de plusieurs fichiers (e.g. d√©tecter des duplications), effectuer des analyses avanc√©es (e.g. complexit√© du code) et suivre l'histoire et le progr√©s d'un probl√®me de code. Deux exemples d'outils que tu peux utiliser sont [SonarQube](https://www.sonarqube.org/) (4,900+ [stars](https://github.com/SonarSource/sonarqube)) et [Code Climate](https://codeclimate.com/) (2,000+ [stars](https://github.com/codeclimate/codeclimate))

Credit: <a href="https://github.com/TheHollidayInn" data-href="https://github.com/TheHollidayInn" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">[Keith Holliday](https://github.com/TheHollidayInn)</a>

<br/>

‚ùå **Autrement:** Avec du code de mauvaise qualit√©, les bugs et la performance seront toujours un probl√®me qu'aucune nouvelle librairie ou fonctionnalit√© de pointe ne peux corriger

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: CodeClimate, un outil commercial qui peux identifier des m√©thodes complexes:

![](https://img.shields.io/badge/üîß%20Example%20using%20Code%20Climate-blue.svg "Examples with CodeClimate")

![alt text](assets/bp-16-yoni-goldberg-quality.png "CodeClimate, a commercial tool that can identify complex methods:")

</details>

<br/><br/>

## ‚ö™ Ô∏è 2.6 V√©rifier ta pr√©paration pour le chaos li√©s a Node

:white_check_mark: **√Ä faire:** Bizarrement, la plupart des tests software concernent uniquement la logique et les donn√©es, mais certaines des pires choses qui peuvent arriver ( et qui sont vraiment difficile √† att√©nuer ) sont les probl√®mes d'infrastructures. Par exemple, est-ce que tu as d√©j√† test√© ce qui arrivera quand la m√©moire du processus est surcharg√©e, ou quand le serveur/process tombe, est-ce que ton syst√®me de monitoring d√©tecte lorsque l'API devient 50% plus lente ? Pour tester et att√©nuer ce type de choses - [l'ing√©nierie du Chaos](https://principlesofchaos.org/) est n√© de Netflix.
Il vise √† fournir une sensibilisation, des frameworks et des outils pour tester la r√©silience de notre application aux probl√®mes chaotiques. Par exemple, l'un de ces fameux outils, [le chaos monkey](https://github.com/Netflix/chaosmonkey), tue al√©atoirement des serveurs pour v√©rifier que notre service peut toujours servir les utilisateurs et ne repose pas sur un unique serveur ( Il y a aussi une version Kubernetes, [kube-monkey](https://github.com/asobti/kube-monkey), qui tue des pods). Tous ces outils fonctionnent au niveau de l'h√©bergeur/la plateforme, mais que se passe-t-il si tu veux g√©n√©rer un chaos Node pour v√©rifier comment ton process g√®re les erreurs non pr√©vus, les rejets de promesse, la surcharge de m√©moire v8 avec l'allocation maximum de 1.7Gb ou est-ce que ton UX reste satisfaisante si l'event loop est bloqu√© r√©guli√®rement ? Pour r√©pondre √† √ßa, j'ai √©crit, [node-chaos](https://github.com/i0natan/node-chaos-monkey) (alpha) qui fournit toute sorte d'actions chaotiques li√©es a Node.
<br/>

‚ùå **Autrement:** Pas d'√©chappatoire ici, la loi de Murphy heurtera votre production sans merci
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Le chaos-Node peut g√©n√©rer toute sortes de d'erreurs Node.js afin que tu puisses tester la r√©silience de ton application au chaos

![alt text](assets/bp-17-yoni-goldberg-chaos-monkey-nodejs.png "Node-chaos can generate all sort of Node.js pranks so you can test how resilience is your app to chaos")

</details>

<br/>

## ‚ö™ Ô∏è2.7 √âviter les fixtures et seeds globals, ajouter les donn√©es par test

:white_check_mark: **√Ä faire:** En suivant la r√®gle d'or (point 0), chaque test doit ajouter et agir sur son propre jeu d'entr√©e en base de donn√©es pour √©viter d'√™tre coupl√©s et faciliter le raisonnement √† propos de la logique du test. En r√©alit√©, cette r√®gle est souvent viol√©e par les testeurs qui remplissent la base de donn√©es avant de lancer les tests (aussi connu sous le nom ‚Äòtest fixture‚Äô) afin d'am√©liorer les performances. M√™me si la performance est effectivement une inqui√©tude valide, elle peut √™tre att√©nu√©e (voir "Component testing"), en revanche, la complexit√© des tests est un chagrin bien plus douloureux qui devrait r√©gir les autres consid√©rations la plupart du temps. En pratique, chaque cas test√© doit explicitement ajouter les entr√©es en base de donn√©es dont il a besoin et n'agir que sur ces entr√©es. Si la performance devient une inqui√©tude critique - un compromis peut se trouver sous la forme de seeds pour les jeux de tests qui ne modifient pas les donn√©es (queries).
<br/>

‚ùå **Autrement:** Certains tests √©choue, le d√©ploiement est annul√©, l'√©quipe va d√©penser un temps pr√©cieux maintenant, est-ce qu'on a un bug ? Investiguons, oh non - il semble que deux tests modifiaient les m√™me donn√©es

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: les tests ne sont pas ind√©pendants et reposent sur un hook global pour des donn√©es globales en DB

![](https://img.shields.io/badge/üîß%20Example%20using%20Mocha-blue.svg "Examples with Mocha")

```javascript
before(async () => {
  //adding sites and admins data to our DB. Where is the data? outside. At some external json or migration framework
  await DB.AddSeedDataFromJson('seed.json');
});
it("When updating site name, get successful confirmation", async () => {
  //I know that site name "portal" exists - I saw it in the seed files
  const siteToUpdate = await SiteService.getSiteByName("Portal");
  const updateNameResult = await SiteService.changeName(siteToUpdate, "newName");
  expect(updateNameResult).to.be(true);
});
it("When querying by site name, get the right site", async () => {
  //I know that site name "portal" exists - I saw it in the seed files
  const siteToCheck = await SiteService.getSiteByName("Portal");
  expect(siteToCheck.name).to.be.equal("Portal"); //Failure! The previous test change the name :[
});

```

<br/>

### :clap: Bien faire les choses, exemple: On peut rester dans le test, chaque test agis sur ses propres donn√©es

```javascript
it("When updating site name, get successful confirmation", async () => {
  //test is adding a fresh new records and acting on the records only
  const siteUnderTest = await SiteService.addSite({
    name: "siteForUpdateTest"
  });
  const updateNameResult = await SiteService.changeName(siteUnderTest, "newName");
  expect(updateNameResult).to.be(true);
});
```

</details>

<br/><br/>

# Section 3Ô∏è‚É£: Tests Frontend

## ‚ö™ Ô∏è 3.1 Separer l'UI des fonctionnalit√©s

:white_check_mark: **√Ä faire:** Lorsqu'on veut tester la logique d'un composant, les d√©tails UI deviennent du bruit qui devrait √™tre extrait, afin que les tests se concentrent purement sur les donn√©es. En pratique, extrait les donn√©es d√©sir√©es du markup d'une fa√ßon abstraite qui n'est pas trop coupl√©e avec l'impl√©mentation graphique, assert seulement les donn√©es (vs des d√©tails graphiques HTML/CSS) et d√©sactive les animations qui ralentissent. Tu peux √™tre tent√© d'√©viter le rendu et ne tester que les parties derri√®re l'UI (e.g. services, actions, store) mais il s'agira de tests fictionnels qui ne ressemblent pas √† la r√©alit√© et ne r√©v√©leront pas les cas ou la bonne donn√©e n'arrive pas √† l'UI.
<br/>

‚ùå **Autrement:** Les donn√©es calcul√©es de ton test peuvent √™tre pr√™tes en 10ms, mais l'ensemble du test durera 500ms (100 tests = 1 min) √† cause d'animation qui ne nous concerne pas dans le cadre du test.
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: S√©parer les d√©tails UI

![](https://img.shields.io/badge/üîß%20Example%20using%20React-blue.svg "Examples with React") ![](https://img.shields.io/badge/üîß%20Example%20using%20React%20Testing%20Library-blue.svg "Examples with react-testing-library")

```javascript
test("When users-list is flagged to show only VIP, should display only VIP members", () => {
  // Arrange
  const allUsers = [{ id: 1, name: "Yoni Goldberg", vip: false }, { id: 2, name: "John Doe", vip: true }];

  // Act
  const { getAllByTestId } = render(<UsersList users={allUsers} showOnlyVIP={true} />);

  // Assert - Extract the data from the UI first
  const allRenderedUsers = getAllByTestId("user").map(uiElement => uiElement.textContent);
  const allRealVIPUsers = allUsers.filter(user => user.vip).map(user => user.name);
  expect(allRenderedUsers).toEqual(allRealVIPUsers); //compare data with data, no UI here
});
```

<br/>

### :thumbsdown: Exemple d'anti pattern: L'assertion m√©lange des d√©tails UX et les donn√©es

```javascript
test("When flagging to show only VIP, should display only VIP members", () => {
  // Arrange
  const allUsers = [{ id: 1, name: "Yoni Goldberg", vip: false }, { id: 2, name: "John Doe", vip: true }];

  // Act
  const { getAllByTestId } = render(<UsersList users={allUsers} showOnlyVIP={true} />);

  // Assert - Mix UI & data in assertion
  expect(getAllByTestId("user")).toEqual('[<li data-test-id="user">John Doe</li>]');
});
```

</details>

<br/><br/>

## ‚ö™ Ô∏è 3.2 Query les √©l√©ments HTML en te basant sur des attributs qui ont peu de chance de changer

:white_check_mark: **√Ä faire:** Query les √©l√©ments HTML en te basant sur des attributs qui ont de grandes chances de survivre √† un changement graphique, contrairement aux s√©lecteurs CSS ou aux labels des forms. Si l'√©l√©ment n'as pas d'attribut de ce type, cr√©e un attribut d√©di√© au test comme 'test-id-submit-sutton'. Utiliser cette m√©thode permet non seulement d'√™tre s√ªr que vos tests fonctionnels/logique ne cassent pas √† cause d'un changement visuel mais il devient √©galement plus clair pour toute votre √©quipe que cet √©l√©ment et son attribut sont utilis√©s par les tests et ne devraient pas √™tre supprim√©s.
<br/>

‚ùå **Autrement:** Tu veux tester la fonctionnalit√© de connexion qui couvre de nombreux composants, logiques et services, tout est configur√© parfaitement - subs, spies, les appels Ajax sont isol√©s. Tout semble parfait. Puis le test √©choue car le designer √† chang√© la class CSS du div de 'thick-border' √† 'thin-border'

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Query un √©l√©ment en utilisant un attribut d√©di√© aux tests

![](https://img.shields.io/badge/üîß%20Example%20using%20React-blue.svg "Examples with React")

```html
// the markup code (part of React component)
<h3>
  <Badge pill className="fixed_badge" variant="dark">
    <span data-test-id="errorsLabel">{value}</span>
    <!-- note the attribute data-test-id -->
  </Badge>
</h3>
```

```javascript
// this example is using react-testing-library
test("Whenever no data is passed to metric, show 0 as default", () => {
  // Arrange
  const metricValue = undefined;

  // Act
  const { getByTestId } = render(<dashboardMetric value={undefined} />);

  expect(getByTestId("errorsLabel").text()).toBe("0");
});
```

<br/>

### :thumbsdown: Exemple d'anti pattern: Compter sur les attributs CSS

```html
<!-- the markup code (part of React component) -->
<span id="metric" className="d-flex-column">{value}</span>
<!-- what if the designer changes the classs? -->
```

```javascript
// this exammple is using enzyme
test("Whenever no data is passed, error metric shows zero", () => {
  // ...

  expect(wrapper.find("[className='d-flex-column']").text()).toBe("0");
});
```

</details>

<br/>

## ‚ö™ Ô∏è 3.3 Lorsque c'est possible, tester avec un composant r√©aliste et totalement rendu

:white_check_mark: **Do:** Lorsqu'ils sont de taille raisonnable, tests tes composants de l'ext√©rieur comme le font tes utilisateurs, rend compl√®tement l'UI, agit dessus, et v√©rifie que l'UI rendu se comporte comme on l'attend.
√âvite toute sorte de mocking, de rendu partiels ou superficiel - cette approche peut r√©sulter en bugs non d√©tect√©s √† cause du manque de d√©tails et rendre plus difficile la maintenance des tests puisque les tests modifient les propri√©t√©s interne (voir le point 'Privil√©gier les tests blackbox'). Si l'un des composants enfants ralentis significativement (e.g animations) ou complique la configuration - consid√®re de le remplacer explicitement avec un faux.

Maintenant que c'est dit, une mise en garde s'impose: cette technique fonctionne pour des petit/moyens composants qui ont un nombre raisonnable de composants enfants. Rendre compl√®tement un composant avec trop d'enfants compliquera le raisonnement √† propos des √©checs de tests (analyse de la cause originelle) et peut √™tre trop lent. Dans ces cas, √©crit seulement quelques tests pour ce parent, et plus de tests pour ses enfants.

<br/>

‚ùå **Autrement:** Lorsque tu fouilles dans les d√©tails internes du composant en invoquant ses m√©thodes priv√©es, et en v√©rifiant l'√©tat interne - tu devras refactoriser tous les tests lorsque tu refactorisera l'impl√©mentation du composant. Est-ce que tu as vraiment la capacit√© de tenir ce niveau de maintenance ?

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Travailler de fa√ßon r√©aliste sur un composant compl√®tement rendu

![](https://img.shields.io/badge/üîß%20Example%20using%20React-blue.svg "Examples with React") ![](https://img.shields.io/badge/üîß%20Example%20using%20Enzyme-blue.svg "Examples with Enzyme")

```javascript
class Calendar extends React.Component {
  static defaultProps = { showFilters: false };

  render() {
    return (
      <div>
        A filters panel with a button to hide/show filters
        <FiltersPanel showFilter={showFilters} title="Choose Filters" />
      </div>
    );
  }
}

//Examples use React & Enzyme
test("Realistic approach: When clicked to show filters, filters are displayed", () => {
  // Arrange
  const wrapper = mount(<Calendar showFilters={false} />);

  // Act
  wrapper.find("button").simulate("click");

  // Assert
  expect(wrapper.text().includes("Choose Filter"));
  // This is how the user will approach this element: by text
});
```

### :thumbsdown: Exemple d'anti pattern: Mocker la r√©alit√© avec un rendu superficiel

```javascript
test("Shallow/mocked approach: When clicked to show filters, filters are displayed", () => {
  // Arrange
  const wrapper = shallow(<Calendar showFilters={false} title="Choose Filter" />);

  // Act
  wrapper
    .find("filtersPanel")
    .instance()
    .showFilters();
  // Tap into the internals, bypass the UI and invoke a method. White-box approach

  // Assert
  expect(wrapper.find("Filter").props()).toEqual({ title: "Choose Filter" });
  // what if we change the prop name or don't pass anything relevant?
});
```

</details>

<br/>

## ‚ö™ Ô∏è 3.4 Ne pas attendre, utiliser la gestion des √©v√®nements asynchrone impl√©ment√© dans les frameworks. Essayer aussi d'acc√©l√©rer les choses

:white_check_mark: **√Ä faire:** Souvent, le temps de compl√©tion de l'unit√© qu'on test est inconnu (e.g animations qui suspendent l'apparition d'√©l√©ments) - Dans ce cas, √©vite d'attendre (e.g. setTimeOut ) et pr√©f√®re des m√©thodes d√©terministe que la plupart des frameworks fournissent. Certaines librairies permettent d'attendre certaines op√©rations (e.g. [Cypress cy.request('url')](https://docs.cypress.io/guides/references/best-practices.html#Unnecessary-Waiting)), d'autres fournissent une API pour attendre comme [@testing-library/dom method wait(expect(element))](https://testing-library.com/docs/guide-disappearance).
Parfois il est plus √©l√©gant de stub la ressource lente, comme une API, une fois que le moment de r√©ponse devient d√©termin√©, le composant peut √™tre re-rendu explicitement. Lorsque l'on d√©pend d'un composant externe qui attend, il peut √™tre utile d'[acc√©l√©rer l'horloge](https://jestjs.io/docs/en/timer-mocks).
Attendre est un pattern √† √©viter puisqu'il force tes tests √† √™tre lent ou risqu√© ( s'ils n'attendent pas assez longtemps ). √Ä chaque fois qu'attendre ou requ√™ter sont in√©vitable et qu'il n'y a pas de support de la part du framework de test, des librairies comme [wait-for-expect](https://www.npmjs.com/package/wait-for-expect) peuvent aider avec une solution demi-d√©terministe.
<br/>

‚ùå **Autrement:** En attendant pour un long moment, les tests seront plus lent. En attendant trop peu, les tests √©choueront si l'unit√© test√©e n'a pas r√©pondu dans les temps. Cela se r√©sume donc √† un compromis entre l'instabilit√© et les mauvaises performances.

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: E2E API qui se r√©soud uniquement lorsque l'op√©ration asynchrone est termin√©e (Cypress)

![](https://img.shields.io/badge/üî®%20Example%20using%20Cypress-blue.svg "Using Cypress to illustrate the idea")
![](https://img.shields.io/badge/üîß%20Example%20using%20React%20Testing%20Library-blue.svg "Examples with react-testing-library")

```javascript
// using Cypress
cy.get("#show-products").click(); // navigate
cy.wait("@products"); // wait for route to appear
// this line will get executed only when the route is ready
```

### :clap: Bien faire les choses, exemple: Librairie de tests qui attend les √©l√©ments du DOM

```javascript
// @testing-library/dom
test("movie title appears", async () => {
  // element is initially not present...

  // wait for appearance
  await wait(() => {
    expect(getByText("the lion king")).toBeInTheDocument();
  });

  // wait for appearance and return the element
  const movie = await waitForElement(() => getByText("the lion king"));
});
```

### :thumbsdown: Exemple d'anti pattern: Code custom qui attend

```javascript
test("movie title appears", async () => {
  // element is initially not present...

  // custom wait logic (caution: simplistic, no timeout)
  const interval = setInterval(() => {
    const found = getByText("the lion king");
    if (found) {
      clearInterval(interval);
      expect(getByText("the lion king")).toBeInTheDocument();
    }
  }, 100);

  // wait for appearance and return the element
  const movie = await waitForElement(() => getByText("the lion king"));
});
```

</details>

<br/>

## ‚ö™ Ô∏è 3.5 Regarder comment le contenu est servi sur le r√©seau

![](https://img.shields.io/badge/üîß%20Example%20using%20Google%20LightHouse-blue.svg "Examples with Lighthouse")

‚úÖ **√Ä faire:** Applique un monitoring active qui s'assure que le chargement de la page sur un vrai r√©seau est optimis√© - √ßa inclue les questions UX comme un chargement lent ou un bundle non minifi√©. Le march√© des outils d'inspection n'est pas petit: des outils basiques comme pingdom](https://www.pingdom.com/), AWS CloudWatch, [gcp StackDriver](https://cloud.google.com/monitoring/uptime-checks/) peuvent √™tre configur√© rapidement pour v√©rifier sur le server est disponible et r√©pond sous un d√©lai raisonnable. Cela ne fait qu'effleurer la surface de ce qui pourrait aller mal, il est donc pr√©f√©rable de choisir des outils sp√©cialis√©s pour le frontend (e.g [lighthouse](https://developers.google.com/web/tools/lighthouse/), [pagespeed](https://developers.google.com/speed/pagespeed/insights/)) et d'effectuer une analyse plus compl√®te. L'attention doit √™tre port√©e sur les sympt√¥mes, les m√©triques qui affectent directement l'exp√©rience utilisateur, comme le temps de chargement d'une page, [meaningful paint](https://scotch.io/courses/10-web-performance-audit-tips-for-your-next-billion-users-in-2018/fmp-first-meaningful-paint), [le temps jusqu'√† ce que la page devienne int√©ractive (TTI)](https://calibreapp.com/blog/time-to-interactive/). En plus de √ßa, on peut √©galement surveiller les causes techniques, comme s'assurer que le contenu est complet, le temps jusqu'au premier byte, l'optimisation des images, s'assurer d'une taille de DOM raisonnable, SSL et autres. Il est recommandable d'avoir ces monitorings complets √† la fois pendant le d√©veloppement, dans le processus CI et surtout - 24h/24 7j/7 sur les serveurs/CDN de production
<br/>

‚ùå **Autrement:** Il doit √™tre d√©cevant de se rendre compte qu'apr√®s tout le soin apport√© √† la cr√©ation d'une interface utilisateur, des tests 100% fonctionnels r√©ussis et des bundles sophistiqu√© - l'exp√©rience utilisateur est horrible et lente √† cause d'une mauvaise configuration du CDN.

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

### :clap: Bien faire les choses, exemple: Rapport d'inspection du temps de chargement avec Lighthouse

![](/assets/lighthouse2.png "Lighthouse page load inspection report")

</details>

<br/>

## ‚ö™ Ô∏è 3.6 Stub les ressources lente ou incertaine comme l'API backend

:white_check_mark: **√Ä faire:** Lorsque tu codes tes tests mainstream ( pas les tests E2E ), √©vite d'impliquer toute ressource qui n'est pas sous ta responsabilit√© et sous ton contr√¥le comme l'API et utilise des stubs √† la place (i.e. test double). En pratique, √† la place de vrais appels √† une API, utilise une librairie de tests double ( comme [Sinon](https://sinonjs.org/), [Test doubles](https://www.npmjs.com/package/testdouble), etc) pour simuler la r√©ponse. L'avantage principal est d'√©viter les comportements incertains - les APIs de tests ou de staging par d√©finition ne sont pas toujours stable et de temps en temps peuvent faire √©chouer tes tests m√™me si ton composant se comporte bien (l'environnement de production n'a pas √©t√© fait pour les tests et limite g√©n√©ralement les requ√™tes). Faire √ßa permettra de simuler plusieurs comportements d'API qui devrait diriger le comportement de ton composant, comme lorsqu'aucune donn√©e n'est trouv√©e ou que l'API √©met une erreur. Enfin et surtout, les appels r√©seau vont √©norm√©ment ralentir les tests.
<br/>

‚ùå **Autrement:** Le test moyen ne tourne pas plus de quelques ms, un API call moyen dure environ 100ms. Cela rend les tests ~20x plus lent.
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Stub ou intercepter les appels API
![](https://img.shields.io/badge/üîß%20Example%20using%20React-blue.svg "Examples with React") ![](https://img.shields.io/badge/üîß%20Example%20using%20React%20Testing%20Library-blue.svg "Examples with react-testing-library")

```javascript
// unit under test
export default function ProductsList() {
  const [products, setProducts] = useState(false);

  const fetchProducts = async () => {
    const products = await axios.get("api/products");
    setProducts(products);
  };

  useEffect(() => {
    fetchProducts();
  }, []);

  return products ? <div>{products}</div> : <div data-test-id="no-products-message">No products</div>;
}

// test
test("When no products exist, show the appropriate message", () => {
  // Arrange
  nock("api")
    .get(`/products`)
    .reply(404);

  // Act
  const { getByTestId } = render(<ProductsList />);

  // Assert
  expect(getByTestId("no-products-message")).toBeTruthy();
});
```

</details>

<br/>

## ‚ö™ Ô∏è 3.7 Avoir quelques tests end-to-end qui lancent le syst√®me entier

:white_check_mark: **√Ä faire:** M√™me si E2E (end-to-end) veut g√©n√©ralement dire test UI avec un vrai navigateur (voir point 3.6), pour d'autre ils signifient des tests qui englobent le syst√®me entier, en incluant le vrai backend. Ce type de tests a beaucoup de valeurs puisqu'ils couvrent les erreurs d'int√©grations entre le frontend et le backend √† cause d'une mauvaise compr√©hension des sch√©mas d'√©changes. Ils sont aussi un moyen efficace de d√©couvrir des erreurs d'int√©grations entre backends (e.g. le microservice A qui envoie le mauvais message au microservice B) et m√™me de d√©tecter des erreurs de d√©ploiement - Il n'y a pas de framework backend pour les tests E2E qui soit aussi simple et mature que les frameworks UI comme [Cypress](https://www.cypress.io/) and [Puppeteer](https://github.com/GoogleChrome/puppeteer). Le point n√©gatif de ces tests, c'est le haut cout de configuration pour un environnement avec autant de composants, et surtout leur fragilit√© - avec 50 microservices, m√™me si un seul √©choue l'ensemble du test E2E √©choue. Pour cette raison, cette technique doit √™tre utilis√©e avec parcimonie, il ne faut pas avoir plus de 1-10 tests de ce type. Ceci dit, m√™me un petit nombre de tests E2E sont susceptibles de d√©tecter les probl√®mes pour lesquels ils sont en place - les d√©fauts de d√©ploiement et d'int√©gration. Il est conseill√© de les ex√©cuter sur un environnement de pr√©-production.

<br/>

‚ùå **Autrement:** L'UI peut investir beaucoup en testant ces fonctionnalit√©s seulement pour r√©aliser que les donn√©es retourn√©es par le backend sont diff√©rentes de ce qui √©tait attendu
<br/>

## ‚ö™ Ô∏è 3.8 Acc√©l√©rer les tests E2E en r√©utilisant les informations d'authentification

:white_check_mark: **√† faire:** Dans des tests E2E qui incluent un vrai backend et utilisent un token utilisateur valide pour les appels API, ce n'est pas rentable d'isoler les tests √† un niveau ou l'utilisateur est cr√©√© et authentifi√© √† chaque requete. √Ä la place, authentifie l'utilisateur une seule fois avant que l'ex√©cution des tests commence (i.e before-all hook), enregistre le token en local et r√©utilise le dans les requetes. √áa semble violer un des principes de test principal - garder les tests autonomes sans associer les ressources. M√™me si c'est une inqui√©tude valide, dans les tests E2E la performance est une inqui√©tude cl√© et cr√©er 1-3 requ√™tes API avant chaque test peut mener a un temps d'execution horrible. R√©utiliser les informations d'authentification ne veut pas dire que les tests doivent agir sur la m√™me entr√©e utilisateur - si le test compte sur les entr√©es utilisateur (e.g. test l'historique de paiement d'un utilisateur) alors assure toi de g√©n√©rer ces entr√©es dans le test et √©vite de les partager avec d'autres tests. Rappelle-toi aussi que le backend peut √™tre simul√© - Si les tests se concentrent sur le frontend, il vaut mieux les isoler et simuler l'API backend (voir point 3.6). 
<br/>

‚ùå **Autrement:** Si on prend 200 cas de tests et qu'on estime l'authentification √† 100ms = 20 secondes simplement pour s'authentifier encore et encore

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Se connecter dans le before-all pas dans le before-each
![](https://img.shields.io/badge/üî®%20Example%20using%20Cypress-blue.svg "Using Cypress to illustrate the idea")

```javascript
let authenticationToken;

// happens before ALL tests run
before(() => {
  cy.request('POST', 'http://localhost:3000/login', {
    username: Cypress.env('username'),
    password: Cypress.env('password'),
  })
  .its('body')
  .then((responseFromLogin) => {
    authenticationToken = responseFromLogin.token;
  })
})

// happens before EACH test
beforeEach(setUser => () {
  cy.visit('/home', {
    onBeforeLoad (win) {
      win.localStorage.setItem('token', JSON.stringify(authenticationToken))
    },
  })
})

```

</details>

<br/>

## ‚ö™ Ô∏è 3.9 Avoir un test E2E qui parcours juste les pages du site

:white_check_mark: **√Ä faire:** Pour le suivi de production et la v√©rification pendant le d√©veloppement, lance un seul test E2E qui visite toute ou la plupart des pages du site et v√©rifie qu'aucune n'√©choue. Ce type de test apporte un bon retour sur investissement puisqu'il est tr√®s simple √† √©crire et maintenir, mais peut d√©tecter tout type d'erreur en incluant les probl√®mes fonctionnels, de r√©seau ou de d√©ploiement. Les autres types de smoke test et sanity check ne sont pas aussi fiable et exhaustifs - certaines √©quipes op√©rationnelles ne font que ping la page d'accueil (production) ou les d√©veloppeurs qui lancent plusieurs tests d'int√©grations qui ne r√©v√®lent pas les probl√®mes de packaging ou li√©s au navigateur. Il est √©vident que ce smoke test ne remplace pas les tests fonctionnels, mais il sert √† d√©tecter rapidement les probl√®mes.

<br/>

‚ùå **Autrement:** Tout peut sembler parfait, tous les tests passent, le health-check de production est √©galement positif, mais le composant de paiement a eu des erreurs de packaging et seul la route /payment ne s'affiche pas

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Smoke test qui parcours toute les pages

![](https://img.shields.io/badge/üî®%20Example%20using%20Cypress-blue.svg "Using Cypress to illustrate the idea")

```javascript
it("When doing smoke testing over all page, should load them all successfully", () => {
  // exemplified using Cypress but can be implemented easily
  // using any E2E suite
  cy.visit("https://mysite.com/home");
  cy.contains("Home");
  cy.contains("https://mysite.com/Login");
  cy.contains("Login");
  cy.contains("https://mysite.com/About");
  cy.contains("About");
});
```

</details>

<br/>

## ‚ö™ Ô∏è 3.10 Exposer les tests comme un document collaboratif

:white_check_mark: **√Ä faire:** En plus d'am√©liorer la stabilit√© de l'application, les tests apportent une autre opportunit√© int√©ressante - ils servent comment une documentation de l'app.
Puisque les tests parlent naturellement √† un niveau moins technique avec un langage plus produit/UX, en utilisant les bons outils, ils peuvent √™tre utilis√©s comme un outil de communication qui aligne toute l'√©quipe - les d√©veloppeurs et les clients.
Par exemple, certains frameworks permettent d'exprimer les parcours et les attentes (i.e les plans de tests) en utilisant un langage lisible par l'humain, donc chaque personne impliqu√©e, y compris les product manager, peuvent lire, approuver et communiquer sur les tests qui sont juste devenu le document de sp√©cification. Cette technique s'appelle aussi 'test d'acceptance' puisqu'il permet au client de d√©finir ses crit√®res de validit√© en langage simple. Il s'agit de [BDD (behavior-driven testing)](https://en.wikipedia.org/wiki/Behavior-driven_development) dans sa forme la plus pure. L'un des frameworks populaire qui permet √ßa est [Cucumber qui a un go√ªt de Javascript](https://github.com/cucumber/cucumber-js), voir l'exemple ci-dessous. Une autre opportunit√© similaire, [StoryBook](https://storybook.js.org/) permet d'exposer les composants UI comme un catalogue graphique dans lequel on peut se promener √† travers les diff√©rents √©tats de chaque composant (e.g afficher une grille avec ou sans filtre, l'afficher avec plusieurs lignes ou aucune, etc), voir √† quoi il ressemble, et comment d√©clencher cet √©tat - cela peut servir aux √©quipe produit mais sert surtout de documentation aux d√©veloppeurs qui utilisent ces composants

‚ùå **Autrement:** Apr√®s avoir investi des ressources dans les tests, ce serait juste dommage de ne pas se servir de cet investissement pour apporter encore plus de valeur

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: D√©crire les tests dans un language humain avec cucumber-js
![](https://img.shields.io/badge/üî®%20Example%20using%20Cucumber-blue.svg "Examples using Cucumber")

```javascript
// this is how one can describe tests using cucumber: plain language that allows anyone to understand and collaborate

Feature: Twitter new tweet

  I want to tweet something in Twitter

  @focus
  Scenario: Tweeting from the home page
    Given I open Twitter home
    Given I click on "New tweet" button
    Given I type "Hello followers!" in the textbox
    Given I click on "Submit" button
    Then I see message "Tweet saved"

```

### :clap: Bien faire les choses, exemple: Visualiser nos composants, leurs √©tats et entr√©es en utilisant Storybook
![](https://img.shields.io/badge/üî®%20Example%20using%20StoryBook-blue.svg "Using StoryBook")

![alt text](assets/story-book.jpg "Storybook")

</details>

<br/><br/>

## ‚ö™ Ô∏è 3.11 D√©tecter les probl√®mes visuels avec des outils automatis√©s

:white_check_mark: **√Ä faire:** Configure des outils automatis√©s pour capturer des screenshots de l'UI quand des changements sont pr√©sent√©s et d√©tecter les probl√®mes visuels comme du contenu qui se superpose ou qui est cass√©. Cela permet de v√©rifier que non seulement les bonnes donn√©es sont pr√©sente mais √©galement que l'utilisateur peut les voir correctement. Cette technique n'est pas tr√®s courante, notre √©tat d'esprit quand on pense aux tests est tourn√© sur les tests fonctionnels mais c'est le visuel que l'utilisateur exp√©rimente et avec le nombre d'appareils diff√©rents disponible il est simple de rater un bug UI important. Certains outils gratuits procurent les bases - g√©n√©rer et enregistrer les screenshots pour qu'ils soient inspect√©s par un humain. M√™me si cette approche peut √™tre suffisante pour de petites apps, son d√©faut comme tout test manuel est qu'il demande une intervention humaine √† chaque fois que quelque chose change. D'un autre c√¥t√©, il est assez difficile de d√©tecter des probl√®mes UI automatiquement √† cause du manque de d√©finition claire - C'est ici que le domaine de 'Visual Regression' entre en jeu et r√©sout ce probl√®me en comparant d'ancienne UI avec les changements les plus r√©cent pour d√©tecter les diff√©rences. Certains outils gratuits peuvent fournir certaines de ces fonctionnalit√©s (e.g [wraith](https://github.com/BBC-News/wraith), [PhantomCSS](<[https://github.com/HuddleEng/PhantomCSS](https://github.com/HuddleEng/PhantomCSS)>)) mais peuvent demander un temps de configuration consid√©rable. Les outils commerciaux (e.g. [Applitools](https://applitools.com/), [Percy.io](https://percy.io/)) vont un peu plus loin en simplifiant l'installation et en apportant des fonctionnalit√©s avanc√©s comme la gestion de l'UI, des alertes, de la capture automatique en √©liminant le "bruit visuel" (e.g. pubs, animations) et m√™me l'analyse du changement DOM/CSS qui a provoqu√© ce probl√®me.

<br/>

‚ùå **Autrement:** Quelle est la qualit√© d'une page qui affiche un bon contenu (100% des tests passent), charge instantan√©ment mais dont la moiti√© du contenu est cach√©e ?

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Une r√©gression visuelle typique - le bon contenu qui est mal servi

![alt text](assets/amazon-visual-regression.jpeg "Amazon page breaks")

<br/>

### :clap: Bien faire les choses, exemple: Configurer wraith pour capturer et comparer les snapshots de l'UI

![](https://img.shields.io/badge/üî®%20Example%20using%20Wraith-blue.svg "Using Wraith")

```
‚Äã# Add as many domains as necessary. Key will act as a label‚Äã

domains:
  english: "http://www.mysite.com"‚Äã

‚Äã# Type screen widths below, here are a couple of examples‚Äã

screen_widths:

  - 600‚Äã
  - 768‚Äã
  - 1024‚Äã
  - 1280‚Äã

‚Äã# Type page URL paths below, here are a couple of examples‚Äã
paths:
  about:
    path: /about
    selector: '.about'‚Äã
  subscribe:
      selector: '.subscribe'‚Äã
    path: /subscribe
```

### :clap: Bien faire les choses, exemple: Utiliser Applitools pour obtenir des comparaisons de snapshots et d'autres fonctionnalit√©s avanc√©es

![](https://img.shields.io/badge/üî®%20Example%20using%20AppliTools-blue.svg "Using Applitools") ![](https://img.shields.io/badge/üî®%20Example%20using%20Cypress-blue.svg "Using Cypress to illustrate the idea")

```javascript
import * as todoPage from "../page-objects/todo-page";

describe("visual validation", () => {
  before(() => todoPage.navigate());
  beforeEach(() => cy.eyesOpen({ appName: "TAU TodoMVC" }));
  afterEach(() => cy.eyesClose());

  it("should look good", () => {
    cy.eyesCheckWindow("empty todo list");
    todoPage.addTodo("Clean room");
    todoPage.addTodo("Learn javascript");
    cy.eyesCheckWindow("two todos");
    todoPage.toggleTodo(0);
    cy.eyesCheckWindow("mark as completed");
  });
});
```

</details>

<br/><br/>

# Section 4Ô∏è‚É£: Mesurer l'efficacit√© des tests

<br/><br/>

## ‚ö™ Ô∏è 4.1 Avoir assez de couverture pour √™tre confiant, ~80% semble √™tre le nombre magique

:white_check_mark: **√Ä faire:** Le but des tests est d'√™tre assez confiant pour avancer rapidement, √©videmment, plus le code est test√© plus l'√©quipe peut √™tre confiante. La couverture (coverage) est une mesure du nombre de lignes de code (et branches, statements, etc) sont atteint par les tests. √Ä partir de quand est-ce suffisant ? 10-30% est √©videmment trop bas pour avoir la moindre id√©e de la validit√© du build, d'un autre c√¥t√© 100% est vraiment co√ªteux et peut d√©vier votre int√©r√™t des parties importantes pour des coins exotiques du code. La r√©ponse longue est que √ßa d√©pend de plusieurs facteurs comme le type de l'application - si tu construis la prochaine g√©n√©ration d'Airbus A380 alors 100% est obligatoire, pour un site d'image de dessin anim√© 50% peut √™tre d√©j√† trop. M√™me si la plupart des amateurs de tests assurent que le bon seuil d√©pend du contexte, la plupart d'entre eux mentionnent √©galement le nombre 80% est une bonne r√®gle g√©n√©rale ([Fowler: ‚Äúin the upper 80s or 90s‚Äù](https://martinfowler.com/bliki/TestCoverage.html)) qui devrait r√©pondre au besoin de la plupart des applications.

Conseil d'impl√©mentation: Tu peux vouloir configurer ton int√©gration continue pour qu'elle ait un seuil de couverture ([Jest link](https://jestjs.io/docs/en/configuration.html#collectcoverage-boolean)) et arr√™ter les builds qui ne r√©pondent pas √† ce standard (il est √©galement possible de configurer un seuil par composant, voir l'exemple ci-dessous). En plus de √ßa, envisage de d√©tecter les baisses de couverture (quand un nouveau commit √† une couverture inf√©rieure) - cela poussera les d√©veloppeurs √† augmenter ou au moins √† conserver la m√™me quantit√© de code test√©. Maintenant que c'est dit, la couverture n'est qu'une mesure, une quantitative, ce n'est pas assez pour dire si vos tests sont robustes. Et il peut aussi √™tre biais√© comme on le verra dans le point suivant

<br/>

‚ùå **Autrement:** La confiance et les nombres vont ensemble, sans vraiment savoir si tu testes la majorit√© du syst√®me, il y aura de la peur, et la peur va te ralentir

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Exemple: Un rapport de couverture classique

![alt text](assets/bp-18-yoni-goldberg-code-coverage.png "A typical coverage report")

<br/>

### :clap: Bien faire les choses, exemple: Configurer la couverture par composant (avec Jest)

![](https://img.shields.io/badge/üî®%20Example%20using%20Jest-blue.svg "Using Jest")

![alt text](assets/bp-18-code-coverage2.jpeg "Setting up coverage per component (using Jest)")

</details>

<br/><br/>

## ‚ö™ Ô∏è 4.2 Inspecter les rapports de couverture pour d√©tecter les sections qui ne sont pas test√©es et autres bizarreries

:white_check_mark: **√Ä faire:** Certains probl√®mes passent juste sous le radar et sont difficiles √† d√©tecter en utilisant des outils traditionnels. Ce ne sont pas vraiment des bugs mais plut√¥t des comportement surprenants de l'application qui peuvent avoir un impact important. Par exemple, souvent certaines parties du code sont rarement voir jamais invoqu√©es - tu penses que la classe 'PricingCalculator' s'occupe toujours de d√©terminer le prix du produit mais il se trouve qu'elle n'est jamais invoqu√©e alors qu'on a plus de 10000 produits en base de donn√©es et de nombreuses ventes ... Les rapports de couvertures t'aident √† d√©terminer si l'application se comporte comme tu penses qu'elle le fait. En plus de √ßa, ils peuvent aussi montrer le type de code qui n'est pas test√© - √ätre inform√© que 80% du code est test√© n'indique pas si les parties critiques sont couvertes. G√©n√©rer des rapports est simple - lance juste ton application en production ou pendant les tests avec le tracking de couverture activ√© et r√©cup√®re des rapports qui montrent √† quelle fr√©quence chaque partie du code est invoqu√©e. Si tu prends ton temps pour regarder ces donn√©es, tu pourras trouver des pi√®ges
<br/>

‚ùå **Autrement:** Si tu ne sais pas quelles parties du code ne sont pas couvertes par les tests, tu ne sais pas d'o√π peuvent venir les probl√®mes

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Qu'est-ce qui ne va pas dans ce rapport de couverture ?

Bas√© sur un sc√©nario r√©el, o√π nous avont track√© l'usage de notre application en QA et detect√© un pattern int√©ressant sur l'authentification (indice: la quantit√© d'erreur de connexion n'est pas proportionnelle, quelque chose ne va pas. Finalement il s'est av√©r√© qu'un bug front-end n'arr√©tait pas d'appeler l'API d'authentification)

![alt text](assets/bp-19-coverage-yoni-goldberg-nodejs-consultant.png "What‚Äôs wrong with this coverage report?")

</details>

<br/><br/>

## ‚ö™ Ô∏è 4.3 Mesurer la couverture logique en utilisant les tests de mutations

:white_check_mark: **√Ä faire:** Les donn√©es de couverture traditionnelles mentent souvent: elles peuvent montrer 100% de couverture, mais aucune de tes fonctions, pas m√™me une seule, ne retourne la bonne r√©ponse. Pourquoi ? Il mesure simplement le nombre de lignes de code que les tests ont visit√©es, mais ils ne v√©rifient pas si les tests ont effectivement test√© quelque chose et v√©rifi√© la r√©ponse. Comme quelqu'un qui effectuerai un voyage d'affaires et qui montre les tampons sur son passeport - Cela ne prouve pas qu'il a travaill√©, seulement qu'il a visit√© quelques a√©roports et h√¥tels.

Les tests de mutations sont l√† pour aider √† mesurer la quantit√© de code qui a effectivement √©t√© TEST√â et pas juste VISIT√â. [Stryker](https://stryker-mutator.io/) est une librairie Javascript pour les tests de mutation et son impl√©mentation est tr√®s soign√©e :

(1) Il change volontairement le code et "implante des bugs". Par exemple, le code newOrder.price === 0 devient newOrder.price != 0. Ces "bugs" sont appel√©s des mutations

(2) Il lance les tests, si tous r√©ussissent, alors on a un probl√®me - Les tests n'ont pas remplis leur r√¥le en d√©couvrant les bugs, les mutations sont dites survivantes. Si les tests √©chouent, c'est bon, les mutations ont √©t√© tu√©es.

Savoir que toute ou la plupart des mutations ont √©t√© tu√©s donne une meilleure confiance qu'un rapport de couverture traditionnel et le temps de configuration est similaire.
<br/>

‚ùå **Autrement:** Tu seras dup√© en croyant que 85% de couverture de code signifie que tes tests d√©tecteront les bugs dans 85% du code

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: 100% de couverture, 0% test√©

![](https://img.shields.io/badge/üî®%20Example%20using%20Stryker-blue.svg "Using Stryker")

```javascript
function addNewOrder(newOrder) {
  logger.log(`Adding new order ${newOrder}`);
  DB.save(newOrder);
  Mailer.sendMail(newOrder.assignee, `A new order was places ${newOrder}`);

  return { approved: true };
}

it("Test addNewOrder, don't use such test names", () => {
  addNewOrder({ assignee: "John@mailer.com", price: 120 });
}); //Triggers 100% code coverage, but it doesn't check anything
```

<br/>

### :clap: Bien faire les choses, exemple: Un rapport Stryker, un outil pour les tests de mutations, qui d√©tecte et compte la quantit√© de code qui n'est pas test√© (Mutations)

![alt text](assets/bp-20-yoni-goldberg-mutation-testing.jpeg "Stryker reports, a tool for mutation testing, detects and counts the amount of code that is not tested (Mutations)")

</details>

<br/><br/>

## ‚ö™ Ô∏è4.4 √âviter les probl√®mes dans le code de test avec les Test linters

:white_check_mark: **√Ä faire:** Un groupe de plugins ESLint ont √©t√© d√©velopp√©s sp√©cifiquement pour inspecter le code de test et d√©tecter les probl√®mes. Par exemple, [eslint-plugin-mocha](https://www.npmjs.com/package/eslint-plugin-mocha) t'avertiras lorsqu'un test est √©crit √† un niveau global (pas un enfant d'une d√©claration describe()) ou lorsque les tests sont [saut√©s](https://mochajs.org/#inclusive-tests), ce qui peut conduire √† une fausse croyance que les tests passent. De fa√ßon similaire, [eslint-plugin-jest](https://github.com/jest-community/eslint-plugin-jest) peut avertir lorsqu'un test n'a pas d'assertion (ne v√©rifie rien)
<br/>

‚ùå **Autrement:** Voir 90% de couverture de code et 100% de tests verts fera appara√Ætre un grand sourire sur ton visage, jusqu'√† ce que tu r√©alises que de nombreux tests ne v√©rifient rien et que plusieurs suites de tests ont √©t√© saut√©es. Avec un peu de chance, tu n'as rien d√©ploy√© bas√© sur de fausses observations

<br/>
<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Un cas de test plein d'erreur, heuresement toutes d√©tect√©s par les Linters

```javascript
describe("Too short description", () => {
  const userToken = userService.getDefaultToken() // *error:no-setup-in-describe, use hooks (sparingly) instead
  it("Some description", () => {});//* error: valid-test-description. Must include the word "Should" + at least 5 words
});

it.skip("Test name", () => {// *error:no-skipped-tests, error:error:no-global-tests. Put tests only under describe or suite
  expect("somevalue"); // error:no-assert
});

it("Test name", () => {*//error:no-identical-title. Assign unique titles to tests
});
```

</details>

<br/><br/>

# Section 5Ô∏è‚É£: CI et autres mesures de qualit√©

<br/><br/>

## ‚ö™ Ô∏è 5.1 Enrichir ses linter et annuler les builds qui ont des probl√®mes de lint

:white_check_mark: **√Ä faire:** Les linters sont un bonus gratuit, avec 5 minutes de configurations, tu as gratuitement un auto-pilote qui surveille ton code et rep√®re les probl√®mes pendant que tu tapes. Les jours o√π les linters √©taient r√©serv√©s √† l'esth√©tique sont termin√©s (pas de point-virgules!). De nos jours, les linters peuvent d√©tecter des probl√®mes s√©rieux comme des erreurs qui ne sont pas thrown correctement et les pertes d'informations. En plus de ta liste de r√®gles basiques (like [ESLint standard](https://www.npmjs.com/package/eslint-plugin-standard) or [Airbnb style](https://www.npmjs.com/package/eslint-config-airbnb)), consid√®re d'ajouter des linters sp√©cialis√©s comme [eslint-plugin-chai-expect](https://www.npmjs.com/package/eslint-plugin-chai-expect) qui peux d√©tecter les tests sans assertions, [eslint-plugin-promise](https://www.npmjs.com/package/eslint-plugin-promise?activeTab=readme) qui d√©tecte les promesses qui ne se resolvent pas (le code ne va jamais continuer), [eslint-plugin-security](https://www.npmjs.com/package/eslint-plugin-security?activeTab=readme) qui peut d√©couvrir les regex qui peuvent √™tre utilis√© pour des attaques DOS, et [eslint-plugin-you-dont-need-lodash-underscore](https://www.npmjs.com/package/eslint-plugin-you-dont-need-lodash-underscore) qui est capable de t'indiquer lorsque le code utilise une m√©thode de librairie qui fait partie des m√©thodes du c≈ìur V8 comme Lodash.\_map(...)

<br/>

‚ùå **Autrement:** Imagine un jour de pluie ou ta production n'arr√™te pas de crasher mais les logs ne montrent aucune stack trace d'erreur. Qu'est-ce qu'il s'est pass√© ? Ton code a malencontreusement √©mis un objet qui n'√©tait pas une erreur et la stack trace a √©t√© perdu, une bonne raison de se taper la t√™te contre les murs. 5 minutes de configuration d'un linter pourraient permettre de d√©tecter cette erreur et sauver la journ√©e

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :thumbsdown: Exemple d'anti pattern: Le mauvais objet d'erreur est √©mit par erreur, aucune stack-trace ne va apparaitre pour cette erreur. Heuresement, ESLint catch le prochain beug de production

![alt text](assets/bp-21-yoni-goldberg-eslint.jpeg "The wrong Error object is thrown mistakenly, no stack-trace will appear for this error. Luckily, ESLint catches the next production bug")

</details>

<br/><br/>

## ‚ö™ Ô∏è 5.2 Raccourcir la boucle de retours avec du CI local pour les d√©veloppeurs

:white_check_mark: **√Ä faire:** Tu utilises un outil de CI avec une bonne inspection de qualit√© comme des tests, du linting, des checks de vuln√©rabilit√©s, etc ? Aide les d√©veloppeurs √† lancer √©galement cette pipeline en local pour solliciter un retour instantan√© et raccourcir la [boucle de feedback](https://www.gocd.org/2016/03/15/are-you-ready-for-continuous-delivery-part-2-feedback-loops/). Pourquoi ? Un processus de tests efficace constitue de nombreuses boucles it√©ratives: (1) essai -> (2) retours -> (3) refactoriser. Plus le retour est rapide, plus le d√©veloppeur peut effectuer d'it√©rations d'am√©liorations par modules et perfectionner le r√©sultat. D'un autre c√¥t√©, lorsque les retours sont lent √† arriver, moins d'am√©liorations peuvent √™tre effectu√©es au sein d'une journ√©e, l'√©quipe peut √™tre d√©j√† pass√©e √† un autre sujet/tache/module et peut ne pas √™tre pr√™te a affiner ce module.

En pratique, certains fournisseurs de CI (Exemple: [CircleCI local CLI](https://circleci.com/docs/2.0/local-cli/)) autorisent le lancement de la pipeline en local. Certains outils commerciaux comme [wallaby fournissent des informations de valeur et des tests](https://wallabyjs.com/) pendant que le d√©veloppeur prototype (pas d'affiliation). Alternativement, tu peux simplement ajouter un script npm au package.json qui lance toute les commandes de qualit√©s (e.g. tests, lint, vuln√©rabilit√©s) - utilise des outils comme [concurrently](https://www.npmjs.com/package/concurrently) pour la parall√©lisation et des code de retour diff√©rents de 0 si l'un des outils √©choue. Maintenant le d√©veloppeur peut juste lancer une commande - e.g. 'npm run quality' - pour recevoir un retour instantan√©. Envisage √©galement d'annuler un commit si le contr√¥le de qualit√© ne passe pas en utilisant githook ([husky can help](https://github.com/typicode/husky))
<br/>

‚ùå **Autrement:** Quand les r√©sultats de qualit√© arrivent le jour suivant le d√©veloppement, les tests ne sont pas une partie fluide du d√©veloppement mais plut√¥t une √©tape formelle apr√®s coup
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Script npm qui effectue une inspection de la qualit√© du code, tout est lanc√© en parall√®le sur demande ou lorsque le d√©veloppeur essaye de push du code

```javascript
"scripts": {
    "inspect:sanity-testing": "mocha **/**--test.js --grep \"sanity\"",
    "inspect:lint": "eslint .",
    "inspect:vulnerabilities": "npm audit",
    "inspect:license": "license-checker --failOn GPLv2",
    "inspect:complexity": "plato .",

    "inspect:all": "concurrently -c \"bgBlue.bold,bgMagenta.bold,yellow\" \"npm:inspect:quick-testing\" \"npm:inspect:lint\" \"npm:inspect:vulnerabilities\" \"npm:inspect:license\""
  },
  "husky": {
    "hooks": {
      "precommit": "npm run inspect:all",
      "prepush": "npm run inspect:all"
    }
}

```

</details>

<br/><br/>

## ‚ö™ Ô∏è5.3 Effectuer des tests e2e sur un vrai miroir de production

:white_check_mark: **√Ä faire:** Les tests end to end (E2E) sont le d√©fi principal de chaque pipeline CI - cr√©er un miroir √©ph√©m√®re de la production √† la vol√©e avec tous les services clouds li√© peut √™tre fastidieux et co√ªteux. Le jeu est de trouver le meilleur compromis: [Docker-compose](https://serverless.com/) permet de cr√©er des environnement dockeris√©s isol√©s avec des containers identiques en utilisant un simple fichier text mais la technologie backend (e.g r√©seau, mod√®le de d√©ploiement) est diff√©rent de la vrai production. Tu peux l'associer √† [‚ÄòAWS Local‚Äô](https://github.com/localstack/localstack) pour travailler avec un stub des services AWS. Si tu es [serverless](https://serverless.com/), plusieurs frameworks comme serverless et [AWS SAM](https://docs.aws.amazon.com/lambda/latest/dg/serverless_app.html) permettent l'invocation locale de code FaaS.

Le large √©cosyst√®me de Kubernetes doit encore formaliser un outil standard pour la mise en miroir locale et CI, bien que de nombreux nouveaux outils soient lanc√©s fr√©quemment. Une des approches est de lancer un 'minimized-Kubernetes' en utilisant des outils comme [Minikube](https://kubernetes.io/docs/setup/minikube/) et [MicroK8s](https://microk8s.io/). Une autre approche est de tester avec un 'vrai-Kebernetes' distant, certains fournisseurs CI (e.g. [Codefresh](https://codefresh.io/)) ont une int√©gration native avec l'environnement Kubernetes et rendent simple le lancement d'une pipeline CI sur le vrai environnement, d'autres permettent d'ex√©cuter des scripts custom sur le Kubernetes distant.
<br/>

‚ùå **Autrement:** Utiliser des technologies diff√©rentes pour la production et pour les tests demande de maintenir deux mod√®les de d√©ploiement et cr√©er une s√©paration entre l'√©quipe dev et l'√©quipe ops.
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Exemple: Une pipeline CI qui g√©n√®re un cluster Kubernetes √† la vol√©e <a href="https://container-solutions.com/dynamic-environments-kubernetes/" data-href="https://container-solutions.com/dynamic-environments-kubernetes/" class="markup--anchor markup--p-anchor" rel="noopener nofollow" target="_blank">([Credit: Dynamic-environments Kubernetes](https://container-solutions.com/dynamic-environments-kubernetes/))</a>

<pre name="38d9" id="38d9" class="graf graf--pre graf-after--p">deploy:<br>stage: deploy<br>image: registry.gitlab.com/gitlab-examples/kubernetes-deploy<br>script:<br>- ./configureCluster.sh $KUBE_CA_PEM_FILE $KUBE_URL $KUBE_TOKEN<br>- kubectl create ns $NAMESPACE<br>- kubectl create secret -n $NAMESPACE docker-registry gitlab-registry --docker-server="$CI_REGISTRY" --docker-username="$CI_REGISTRY_USER" --docker-password="$CI_REGISTRY_PASSWORD" --docker-email="$GITLAB_USER_EMAIL"<br>- mkdir .generated<br>- echo "$CI_BUILD_REF_NAME-$CI_BUILD_REF"<br>- sed -e "s/TAG/$CI_BUILD_REF_NAME-$CI_BUILD_REF/g" templates/deals.yaml | tee ".generated/deals.yaml"<br>- kubectl apply --namespace $NAMESPACE -f .generated/deals.yaml<br>- kubectl apply --namespace $NAMESPACE -f templates/my-sock-shop.yaml<br>environment:<br>name: test-for-ci</pre>

</details>

<br/><br/>

## ‚ö™ Ô∏è5.4 Parall√©liser l'ex√©cution des tests

:white_check_mark: **√Ä faire:** Lorsque c'est fait correctement, les tests sont tes amis 24/7 en fournissant un retour quasi instantan√©. En pratique, ex√©cuter 500 tests unitaires li√©s au processeur sur un seul thread peut prendre trop longtemps. Heureusement, les outils de tests et les plateformes CI moderne (comme [Jest](https://github.com/facebook/jest), [AVA](https://github.com/avajs/ava) et [Mocha extensions](https://github.com/yandex/mocha-parallel-tests)) peuvent parall√©liser les tests sur plusieurs processus et am√©liorer significativement le temps de retour. Certains fournisseurs CI font √©galement de la parall√©lisation de tests √† travers des containers (!) ce qui raccourcis encore plus la boucle de retour. Que ce soit localement sur plusieurs processus, ou sur un serveur Cloud avec plusieurs machines - parall√©liser demande de garder les tests autonomes puisqu'ils peuvent tourner sur diff√©rents processus.

‚ùå **Autrement:** Obtenir les r√©sultats de tests 1h apr√®s avoir publi√© du nouveau code, pendant que tu es d√©j√† en train de coder la fonctionnalit√© suivante, est une bonne recette pour rendre les tests moins pertinents
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple: Mocha parallel & Jest distancent facilement le Mocha traditionnel grace √† la parall√©lisation ([Credit: JavaScript Test-Runners Benchmark](https://medium.com/dailyjs/javascript-test-runners-benchmark-3a78d4117b4))

![alt text](assets/bp-24-yonigoldberg-jest-parallel.png "Mocha parallel & Jest easily outrun the traditional Mocha thanks to testing parallelization (Credit: JavaScript Test-Runners Benchmark)")

</details>

<br/><br/>

## ‚ö™ Ô∏è5.5 Rester loin des probl√®mes l√©gaux en utilisants des v√©rifications de license et de plagiat

:white_check_mark: **√Ä faire:** Les probl√®mes de licences et de plagiat ne sont probablement pas au centre de votre attention pour l'instant, mais pourquoi ne pas cocher √©galement cette case en 10 minutes ? Plusieurs packages npm comme [license check](https://www.npmjs.com/package/license-checker) et [plagiarism check](https://www.npmjs.com/package/plagiarism-checker) (commerciaux avec un essai gratuit) peuvent √™tre facilement int√©gr√© dans ta pipeline CI et inspecter les probl√®mes tels que les d√©pendances avec des licences restrictives ou du code qui a √©t√© copi√©-coll√© √† partir de Stack Overflow et qui violerai certains droits d'auteur

‚ùå **Autrement:** Involontairement, les d√©veloppeurs peuvent utiliser un package avec une license inappropri√©, ou copier/coller du code commercial et tomber sur des probl√®mes l√©gaux
<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Bien faire les choses, exemple:

```javascript
//install license-checker in your CI environment or also locally
npm install -g license-checker

//ask it to scan all licenses and fail with exit code other than 0 if it found unauthorized license. The CI system should catch this failure and stop the build
license-checker --summary --failOn BSD

```

<br/>

![alt text](assets/bp-25-nodejs-licsense.png)

</details>

<br/><br/>

## ‚ö™ Ô∏è5.6 Inspecter constamment les d√©pendences vuln√©rables

:white_check_mark: **√Ä faire:** M√™me les d√©pendances les plus r√©put√©es comme Express ont des vuln√©rabilit√©s connues. Cela peut √™tre apprivois√© facilement avec des outils de la communaut√© comme [npm audit](https://docs.npmjs.com/getting-started/running-a-security-audit), ou des outils commerciaux comme [snyk](https://snyk.io/) (qui offre √©galement une version de la communaut√© gratuite). Les deux peuvent √™tre appel√©s depuis ton CI √† chaque build

‚ùå **Autrement:** Garder ton code exempt de vuln√©rabilit√©s sans les outils appropri√©s demande de suivre constamment les publications en ligne √† propos des nouvelles menaces. Plut√¥t fastidieux.

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Exemple: R√©sultat d'audit Npm

![alt text](assets/bp-26-npm-audit-snyk.png "NPM Audit result")

</details>

<br/><br/>

## ‚ö™ Ô∏è5.7 Automatiser les mises-√†-jour de d√©pendences

:white_check_mark: **√Ä faire:** L'introduction r√©cente du package-lock.json par Yarn et npm √† introduit un vrai d√©fi (la route vers l'enfer est pav√©e de bonnes intentions) - par d√©faut maintenant, les packages ne sont pas mis √† jour. M√™me une √©quipe qui lance plusieurs nouveaux d√©ploiements avec 'npm install' & 'npm update' n'aura pas de nouvelles mise √† jour. Cela conduit au mieux, √† des d√©pendances √† des packages de qualit√© inf√©rieure, au pire √† du code vuln√©rable. Les √©quipes d√©pendent maintenant de la bonne volont√© et de la m√©moire des d√©veloppeur pour mettre √† jour manuellement le package.json ou utiliser des outils [comme ncu](https://www.npmjs.com/package/npm-check-updates). Une m√©thode plus fiable pourrait √™tre d'automatiser le processus de r√©cup√©ration des versions de d√©pendances les plus fiables, bien qu'il n'y ait pas de solutions miracle, il y a deux possibilit√©s d'automatisation:

(1) Le CI peut faire √©chouer les builds qui ont des d√©pendances obsol√®tes - en utilisant des outils comme [‚Äònpm outdated‚Äô](https://docs.npmjs.com/cli/outdated) ou 'npm-check-updates (ncu)'. Faire √ßa forcera les d√©veloppeurs √† mettre √† jour les d√©pendances.

(2) Utiliser un outil commercial qui peut scanner le code et envoyer automatiquement une pull-request avec les d√©pendances mises √† jour. La question int√©ressante restante est, quel devrait √™tre la politique de mises √† jour - Mettre √† jour chaque patch g√©n√®re trop de surcharge, mettre √† jour juste apr√®s une release majeure peut introduire une version instable (de nombreuses vuln√©rabilit√©s sont d√©couverte dans les premiers jours apr√®s la release, [voir l'incident](https://nodesource.com/blog/a-high-level-post-mortem-of-the-eslint-scope-security-incident/) eslint-scope).

Une politique de mise √† jour efficace peut autoriser une 'p√©riode d'acquisition' - laisser le code en retard par rapport √† @latest pour quelque temps et versions avant de consid√©rer la copie locale comme obsol√®te (e.g la version locale est 1.3.1 et la version du repo est 1.3.8)
<br/>

‚ùå **Autrement:** Ta production utilisera des packages qui ont √©t√© tagg√© explicitement par leurs auteurs comme risqu√©es

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Exemple: [ncu](https://www.npmjs.com/package/npm-check-updates) peut √™tre utilis√© manuellement ou dans une pipeline CI pour d√©tecter √† quel point le code est en retard vis a vis des derni√®res versions

![alt text](assets/bp-27-yoni-goldberg-npm.png "ncu can be used manually or within a CI pipeline to detect to which extent the code lag behind the latest versions")

</details>

<br/><br/>

## ‚ö™ Ô∏è 5.8 Autres conseils CI, sans rapports avec Node

:white_check_mark: **√Ä faire:** Ce post se concentre sur les conseils de tests qui sont en lien avec, ou peuvent √™tre illustr√©s, avec Node JS. Ce point, cependant, regroupe quelques conseils sans rapports avec Node qui sont bien connus

 <ol class="postList"><li name="e3e4" id="e3e4" class="graf graf--li graf-after--p">Utilise une syntaxe d√©clarative. C'est la seule option pour la plupart des fournisseurs mais d'anciennes versions de Jenkins autorisent l'utilisation du code ou de l'UI</li><li name="1fdc" id="1fdc" class="graf graf--li graf-after--li">Choisis un fournisseur qui a une int√©gration Docker native</li><li name="edcd" id="edcd" class="graf graf--li graf-after--li">√âchoue rapidement, lance les tests les plus rapides d'abord. Cr√©e des 'tests de fum√©e' pour certaines √©tapes qui regroupe plusieurs inspections rapide (e.g liting, tests unitaires) et fourni des commentaires rapides √† celui qui commit le code</li><li name="0375" id="0375" class="graf graf--li graf-after--li">Facilite le parcours des informations de build, cela inclut les rapports de tests, de couverture, de mutation, les logs ..etc</li><li name="df82" id="df82" class="graf graf--li graf-after--li">Cr√©e plusieurs pipelines/jobs pour chaque √©v√©nement, r√©utiliser les √©tapes entre eux. Par exemple, configure un job pour les commits de features sur une branche et un diff√©rent pour une PR sur master. Laisse chacun r√©utiliser la logique en utilisant des √©tapes partag√©es (la plupart des fournisseurs ont des m√©canismes pour r√©utiliser le code)</li><li name="19b0" id="19b0" class="graf graf--li graf-after--li">Ne mets jamais de secrets dans la d√©claration du job, r√©cup√®re-les depuis un secret store ou depuis les configurations du job</li><li name="b70d" id="b70d" class="graf graf--li graf-after--li">Augmente explicitement la version dans un build de release, ou au moins v√©rifie que le d√©veloppeur l'a fait</li><li name="957c" id="957c" class="graf graf--li graf-after--li">Build une fois et effectue toute les inspections sur l'artefact de build (e.g. Docker image)</li><li name="339b" id="339b" class="graf graf--li graf-after--li">Test dans un environnement √©ph√©m√®re qui ne change pas d'√©tat entre les builds. Le cache des nodes peut √™tre la seule exception</li></ol>
<br/>

‚ùå **Autrement:** Tu rateras des ann√©es de sagesse

<br/><br/>

## ‚ö™ Ô∏è 5.9 Structure de build: Lancer les m√™mes √©tapes CI sur plusieurs versions de Node

:white_check_mark: **√Ä faire:** Le contr√¥le de qualit√© est un jeu de hasard, plus tu couvres de terrain, plus tu as de chance de d√©tecter les probl√®mes rapidement. Quand tu d√©veloppes des packages r√©utilisable ou que tu lances une production avec plusieurs clients qui ont diff√©rentes configurations et versions de Node, le CI doit lancer la pipeline de tests sur toutes les configurations possible. Par exemple, imaginons qu'on utilise MySQL pour certains clients et Postgres pour d'autres - Certains fournisseurs CI supportent une fonctionnalit√©e appel√©e 'Matrix' qui permet de lancer les tests contre toutes les permutations de MySQL, Postgres et plusieurs versions de Node comme 8, 9 et 10. Cela peut se faire en utilisant seulement des configurations sans efforts suppl√©mentaire (en consid√©rant que tu as des tests ou d'autres contr√¥les de qualit√©s). D'autres CIs qui ne supportent pas Matrix peuvent avoir des extensions qui permettent √ßa
<br/>

‚ùå **Autrement:** Apr√®s avoir fait tout le travail d'√©crire des tests, va-t-on laisser passer des bugs seulement √† cause de probl√®mes de configurations ?

<br/>

<details><summary>‚úè <b>Exemple de code</b></summary>

<br/>

### :clap: Exemple: Utiliser les d√©finition de build de Travis (fournisseur CI) pour lancer le m√™me test sur plusieurs versions de Node

<pre name="f909" id="f909" class="graf graf--pre graf-after--p">language: node_js<br>node_js:<br>  - "7"<br>  - "6"<br>  - "5"<br>  - "4"<br>install:<br>  - npm install<br>script:<br>  - npm run test</pre>
</details>

<br/><br/>

# L'√©quipe

## Yoni Goldberg

<br/>
<img width="480px" src="assets/yoni-goldberg.jpg"/>
<br/>

**R√¥le:** Auteur

**√Ä propos:** Je suis un consultant ind√©pendant qui travaille avec des entreprises Fortune 500 et des startups pour peaufiner leurs applications JS et Node.JS. Plus qu'aucun autre sujet, je suis fascin√© par et vise √† ma√Ætriser l'art du test. Je suis aussi l'auteur de [Node.js Best Practices](https://github.com/goldbergyoni/nodebestpractices)

**üìó Cours en ligne:** Tu aimes ce guide et tu veux pousser tes comp√©tences de test √† l'extreme ? Pense √† regarder mon cours complet [Testing Node.js & JavaScript From A To Z](https://www.testjavascript.com)

<br/>

**Me suivre:**

- [üê¶ Twitter](https://twitter.com/goldbergyoni/)
- [üìû Contact](https://testjavascript.com/contact-2/)
- [‚úâÔ∏è Newsletter](https://testjavascript.com/newsletter//)

<br/>
<hr/>
<br/>

## [Bruno Scheufler](https://github.com/BrunoScheufler)

**R√¥le:** R√©viseur et conseiller technique

A pris soin de revoir, am√©liorer, linter et peaufiner tout les textes

**√Ä propos:** Ing√©nieur web full-stack, passion√© par Node.js et GraphQL

<hr/>
<br/>

## [Ido Richter](https://github.com/idori)

**R√¥le:** Concept, design et bons conseils

**√Ä propos:** Un d√©veloppeur front-end averti, expert CSS et maniaque des √©mojis

## [Kyle Martin](https://github.com/js-kyle)

**R√¥le:** Aide √† faire tourner ce projet, et revois les pratiques li√©s √† la s√©curit√©

**√Ä propos:** Aime travailler sur des projets Node.JS et la s√©curit√© des applications web.

## Contributors ‚ú®

Merci √† ces merveilleuses personnes qui ont contribu√© √† ce repo!

<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tr>
    <td align="center"><a href="http://geospatialscott.blogspot.com/"><img src="https://avatars3.githubusercontent.com/u/1326248?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Scott Davis</b></sub></a><br /><a href="#content-stdavis" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/AdrienRedon"><img src="https://avatars2.githubusercontent.com/u/5978436?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Adrien REDON</b></sub></a><br /><a href="#content-AdrienRedon" title="Content">üñã</a></td>
    <td align="center"><a href="https://twitter.com/NoriSte"><img src="https://avatars0.githubusercontent.com/u/173663?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Stefano Magni</b></sub></a><br /><a href="#content-NoriSte" title="Content">üñã</a></td>
    <td align="center"><a href="https://www.joer.im"><img src="https://avatars2.githubusercontent.com/u/47742486?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Yeoh Joer</b></sub></a><br /><a href="#content-yjoer" title="Content">üñã</a></td>
    <td align="center"><a href="http://jhonnymoreira.dev"><img src="https://avatars0.githubusercontent.com/u/2177742?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Jhonny Moreira</b></sub></a><br /><a href="#content-jhonnymoreira" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/Germanika"><img src="https://avatars2.githubusercontent.com/u/8846678?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Ian Germann</b></sub></a><br /><a href="#content-Germanika" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/AbdelrahmanHafez"><img src="https://avatars3.githubusercontent.com/u/19984935?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Hafez</b></sub></a><br /><a href="#content-AbdelrahmanHafez" title="Content">üñã</a></td>
  </tr>
  <tr>
    <td align="center"><a href="http://www.ruxandrafediuc.com"><img src="https://avatars1.githubusercontent.com/u/11021586?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Ruxandra Fediuc</b></sub></a><br /><a href="#content-ruxandrafed" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/jacklee814"><img src="https://avatars0.githubusercontent.com/u/9951291?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Jack</b></sub></a><br /><a href="#content-jacklee814" title="Content">üñã</a></td>
    <td align="center"><a href="https://www.petercarrero.com"><img src="https://avatars0.githubusercontent.com/u/231727?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Peter Carrero</b></sub></a><br /><a href="#content-aloyr" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/huhgawz"><img src="https://avatars3.githubusercontent.com/u/369338?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Huhgawz</b></sub></a><br /><a href="#content-huhgawz" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/haakonmb"><img src="https://avatars1.githubusercontent.com/u/7099302?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Haakon Borch</b></sub></a><br /><a href="#content-haakonmb" title="Content">üñã</a></td>
    <td align="center"><a href="https://jaimemendoza.com/"><img src="https://avatars3.githubusercontent.com/u/5395811?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Jaime Mendoza</b></sub></a><br /><a href="#content-jaimemendozadev" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/camerondunford"><img src="https://avatars0.githubusercontent.com/u/840612?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Cameron Dunford</b></sub></a><br /><a href="#content-camerondunford" title="Content">üñã</a></td>
  </tr>
  <tr>
    <td align="center"><a href="https://github.com/shadowspawn"><img src="https://avatars1.githubusercontent.com/u/15719847?v=4?s=100" width="100px;" alt=""/><br /><sub><b>John Gee</b></sub></a><br /><a href="#content-shadowspawn" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/aurelijusrozenas"><img src="https://avatars0.githubusercontent.com/u/3273544?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Aurelijus Ro≈æƒónas</b></sub></a><br /><a href="#content-aurelijusrozenas" title="Content">üñã</a></td>
    <td align="center"><a href="http://aaronshivers.com"><img src="https://avatars2.githubusercontent.com/u/42848750?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Aaron</b></sub></a><br /><a href="#content-aaronshivers" title="Content">üñã</a></td>
    <td align="center"><a href="https://tomdoes.tech/"><img src="https://avatars1.githubusercontent.com/u/8683577?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Tom Nagle</b></sub></a><br /><a href="#content-tomanagle" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/yvesyao"><img src="https://avatars0.githubusercontent.com/u/7723729?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Yves yao</b></sub></a><br /><a href="#content-yvesyao" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/Userbit"><img src="https://avatars1.githubusercontent.com/u/34487074?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Userbit</b></sub></a><br /><a href="#content-Userbit" title="Content">üñã</a></td>
    <td align="center"><a href="https://glaucialemos.netlify.com/"><img src="https://avatars0.githubusercontent.com/u/1631477?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Glaucia Lemos</b></sub></a><br /><a href="#maintenance-glaucia86" title="Maintenance">üöß</a></td>
  </tr>
  <tr>
    <td align="center"><a href="https://twitter.com/koooge"><img src="https://avatars2.githubusercontent.com/u/7419215?v=4?s=100" width="100px;" alt=""/><br /><sub><b>koooge</b></sub></a><br /><a href="#content-koooge" title="Content">üñã</a></td>
    <td align="center"><a href="https://twitter.com/michalbiesiada"><img src="https://avatars0.githubusercontent.com/u/18367606?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Michal</b></sub></a><br /><a href="#content-mbiesiad" title="Content">üñã</a></td>
    <td align="center"><a href="http://roywalker.me"><img src="https://avatars0.githubusercontent.com/u/611846?v=4?s=100" width="100px;" alt=""/><br /><sub><b>roywalker</b></sub></a><br /><a href="#content-roywalker" title="Content">üñã</a></td>
    <td align="center"><a href="https://dangen-effy.github.io/"><img src="https://avatars3.githubusercontent.com/u/23185799?v=4?s=100" width="100px;" alt=""/><br /><sub><b>dangen</b></sub></a><br /><a href="#content-dangen-effy" title="Content">üñã</a></td>
    <td align="center"><a href="https://dev.to/mbiesiad"><img src="https://avatars1.githubusercontent.com/u/60202305?v=4?s=100" width="100px;" alt=""/><br /><sub><b>biesiadamich</b></sub></a><br /><a href="#content-biesiadamich" title="Content">üñã</a></td>
    <td align="center"><a href="https://tarojsx.github.io"><img src="https://avatars3.githubusercontent.com/u/127009?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Yanlin Jiang</b></sub></a><br /><a href="#content-cncolder" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/sanguino"><img src="https://avatars2.githubusercontent.com/u/2077168?v=4?s=100" width="100px;" alt=""/><br /><sub><b>sanguino</b></sub></a><br /><a href="#content-sanguino" title="Content">üñã</a></td>
  </tr>
  <tr>
    <td align="center"><a href="https://github.com/MorganGeek"><img src="https://avatars0.githubusercontent.com/u/3721240?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Morgan</b></sub></a><br /><a href="#content-MorganGeek" title="Content">üñã</a></td>
    <td align="center"><a href="https://luk4s.dev"><img src="https://avatars0.githubusercontent.com/u/8350985?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Lukas Bischof</b></sub></a><br /><a href="https://github.com/goldbergyoni/javascript-testing-best-practices/commits?author=lukasbischof" title="Tests">‚ö†Ô∏è</a> <a href="#content-lukasbischof" title="Content">üñã</a></td>
    <td align="center"><a href="https://juanmaruiz.surge.sh"><img src="https://avatars2.githubusercontent.com/u/1837650?v=4?s=100" width="100px;" alt=""/><br /><sub><b>JuanMa Ruiz</b></sub></a><br /><a href="#content-JuanMaRuiz" title="Content">üñã</a></td>
    <td align="center"><a href="https://luisangelorjr.com.br"><img src="https://avatars3.githubusercontent.com/u/22268900?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Lu√≠s √Çngelo Rodrigues Jr.</b></sub></a><br /><a href="#content-luisangelorjr" title="Content">üñã</a></td>
    <td align="center"><a href="https://jfernandezpe.wordpress.com/"><img src="https://avatars0.githubusercontent.com/u/12046620?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Jos√© Fern√°ndez</b></sub></a><br /><a href="#content-jfernandezpe" title="Content">üñã</a></td>
    <td align="center"><a href="http://www.linkedin.com/in/AlejandroGutierrezB"><img src="https://avatars3.githubusercontent.com/u/56408597?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Alejandro Gutierrez Barcenilla</b></sub></a><br /><a href="#content-AlejandroGutierrezB" title="Content">üñã</a></td>
    <td align="center"><a href="https://github.com/jasonandmonte"><img src="https://avatars1.githubusercontent.com/u/30088000?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Jason</b></sub></a><br /><a href="#content-jasonandmonte" title="Content">üñã</a></td>
  </tr>
  <tr>
    <td align="center"><a href="https://github.com/otavionetoca"><img src="https://avatars.githubusercontent.com/u/11263232?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Otavio Araujo</b></sub></a><br /><a href="https://github.com/goldbergyoni/javascript-testing-best-practices/commits?author=otavionetoca" title="Tests">‚ö†Ô∏è</a> <a href="#content-otavionetoca" title="Content">üñã</a></td>
    <td align="center"><a href="https://contributor.pw"><img src="https://avatars.githubusercontent.com/u/5027939?v=4?s=100" width="100px;" alt=""/><br /><sub><b>Alex Ivanov</b></sub></a><br /><a href="#content-contributorpw" title="Content">üñã</a></td>
  </tr>
</table>

<!-- markdownlint-restore -->
<!-- prettier-ignore-end -->

<!-- ALL-CONTRIBUTORS-LIST:END -->
